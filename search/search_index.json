{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"KurrawongAI Docs <p>A central repository of information at KurrawongAI.</p> <p>Here we document how to install, configure and use all of the KurrawongAI products and 3rd party products that we support.</p> <p>We also provide user-tailored documentation for many clients too, just to them. These may be the information here, with organisation-specific additions visible only to them, or entirely custom information.</p>"},{"location":"#getting-around","title":"Getting Around","text":"<p>Information in the knowledge base can be discovered in the two following ways:</p> <ol> <li>Using the Navigation Panel<ul> <li>The navigation panel provides a familiar, tree-like structure from which the knowledge base can be explored.</li> </ul> </li> <li>Using Search<ul> <li>The Search bar, located at the top of the navigation panel, can be used to search for keywords or phrases in the knowledge base.</li> </ul> </li> </ol>"},{"location":"#about-us","title":"About Us","text":"<p>KurrawongAI is a small, Australian-based, company enabling organisations to take control of their data.</p> <p>We use data modelling, data governance and data systems implementation expertise, all based on Semantic Web and Knowledge Graph principles, to ensure data is in the richest, most open and most extensible form it can be.</p> <p>We use knowledge graphs for data storage, as a transfer format, when serialised, and as inputs to advanced reasoning and data processing tasks, such as for Machine Learning and Artificial Intelligence applications.</p>"},{"location":"concepts/agents/patterns/","title":"Agent Patterns","text":"<p>Scope</p> <p>This content is in intended to convey Best Practice patterns in agent authority content</p> <p>Audience</p> <p>Technical agent authority creators.</p> <p>All the patterns documented here assume the use of Semantic Web methods for data management and access. </p> <p>Outcome</p> <p>Technical agent authority creators should learn both what KurrawongAI considers to be Best Practice for certain aspects of agent authorities and also how KurrawongAI and other agent creation and publication tools support the pattern.</p>"},{"location":"concepts/agents/patterns/#constructing-agent-identifiers","title":"Constructing Agent Identifiers","text":"<p>What kind of Persistent Identifiers should we mint for agents?</p>"},{"location":"concepts/agents/patterns/#context","title":"Context","text":"<p>Agents, be they individual persons or organizations, cannot be reliably identified via their names and should be uniquely identified.</p>"},{"location":"concepts/agents/patterns/#solution","title":"Solution","text":"<p>Agents can be uniquely and persistently identified, much the same as we would identify concepts in a vocabulary. We can add a Persistent Identifier (PID) using one of two approaches:</p> <ol> <li>with a pre-structured pattern specified in a catalogue system or metadata profile</li> <li>by reusing an existing known identifier for that agent </li> </ol>"},{"location":"concepts/agents/patterns/#pre-structured-identifier-patterns","title":"Pre-structured identifier patterns","text":"<p>Agent PIDs may follow a structure mandated by some cataloguing system or metadata profile. Below are examples from the Indigenous Data Network and the Linked Data PID Register.</p>"},{"location":"concepts/agents/patterns/#indigenous-data-network","title":"Indigenous Data Network","text":"<p>The IDN Catalogue Profile specifies an IRI structure for a PID:  </p> <ul> <li>A stem: <code>https://data.idnau.org/pid/</code></li> <li>A subdirectory indicating a sub-class - for an agent, this will usually be an organisation or a person, indicated by <code>/org/</code> and <code>/person/</code> respectively:</li> <li><code>https://data.idnau.org/pid/org/</code></li> <li><code>https://data.idnau.org/pid/person/</code></li> <li>A suffix. This might be completely opaque (such as from the UUID scheme) or based on an existing identifier for the agent (see ), e.g. </li> <li><code>https://data.idnau.org/pid/org/18d04115-4633-4aed-b164-ac3c209b4307</code> [UUID suffix]</li> <li><code>https://data.idnau.org/pid/person/34d5d6aa-a5b7-4e3a-91f8-117ffeb474d1</code> [UUID suffix]</li> </ul>"},{"location":"concepts/agents/patterns/#linked-data-pid-register","title":"Linked Data PID Register","text":"<p>The Australian Government Linked Data Working Group (AGLDWG) maintains a PID Register for various entities, including Organisations. In this registry, an Organisation PID is made up of:</p> <ul> <li>A stem: <code>https://linked.data.gov.au/</code> </li> <li>A subdirectory indicating a class, e.g. <code>https://linked.data.gov.au/org/</code></li> <li>An identifier, e.g. <code>https://linked.data.gov.au/org/abs</code> [Australian Bureau of Statistics]</li> </ul>"},{"location":"concepts/agents/patterns/#reusing-identifiers-as-a-pid","title":"Reusing identifiers as a PID","text":"<p>If an agent has an existing known identifier, such as an ORCID for persons or a Research Organization Registry ID for Organizations, you can reuse that in its entirety as a PID.</p> <p>Some widely used agentic systems that mint identifiers include:</p> <ul> <li>Open Researcher and Contributor ID (https://orcid.org)</li> <li>Research Organization Registry (https://ror.org)</li> <li>Australian Business Number (https://abnregistration.com.au)</li> </ul> <p>ORCID example</p> <p><pre><code>PREFIX aarr: &lt;https://data.idnau.org/pid/vocab/aarr/&gt;\nPREFIX dcat: &lt;http://www.w3.org/ns/dcat#&gt;\nPREFIX id: &lt;http://id.loc.gov/vocabulary/identifiers/&gt;\nPREFIX sdo: &lt;https://schema.org/&gt;\n\n&lt;https://orcid.org/0000-0001-5640-3202&gt;\n    a sdo:Person ;\n    dcat:qualifiedRelation [\n    a dcat:Relationship ;\n       dcat:hadRole aarr:memberOf ;\n       sdo:agent &lt;https://data.idnau.org/pid/org/dewr&gt; \n    ] ;\n    sdo:name \"Les Kneebone\" ;\n    sdo:identifier \"https://orcid.org/0000-0001-5640-3202\"^^id:orcid ;\n.\n</code></pre> In this example, an ORCID has been used as the IRI. Additionally, the ORCID has optionally been added as sdo:identifier. </p> <p>Example: Research Organization Registry (ROR) identifier</p> <pre><code>PREFIX id: &lt;http://id.loc.gov/vocabulary/identifiers/&gt;\nPREFIX sdo: &lt;https://schema.org/&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n&lt;https://ror.org/03y7q9t39&gt;\n    a sdo:Organization ;\n    sdo:url \"https://www.canterbury.ac.nz\"^^xsd:anyURI ;\n    sdo:name \"University of Canterbury\" ;\n    sdo:identifier \n       \"https://ror.org/03y7q9t39\"^^id:ror ,\n       \"https://isni.org/isni/0000000513611983\"^^id:isni ;\n.\n</code></pre> <p>In the ROR example, and ROR ID has been used as the IRI. Additionally, an ID from both https://ror.org and https://isni.oclc.org is also expressed as sdo:identifier.</p>"},{"location":"concepts/agents/patterns/#pid-suffix-for-a-pre-structured-identifier","title":"PID Suffix for a Pre-structured Identifier","text":"<p>If using a Pre-structured identifier patter, there may be options for minting a suffix. You might use:</p> <ul> <li>a name or acronym from the agent</li> <li>an identifier associated with the agent</li> <li>an opaque string such as from the UUID scheme</li> </ul> <p>Note</p> <p>Agent names or acronyms may not be unique in the context of your database! Exercise caution when using an agent name for a PID suffix.</p> <p>Example: acronym as suffix <pre><code>&lt;https://data.idnau.org/pid/org/abs-coatsis&gt;\n</code></pre> Example: identifier as suffix <pre><code>&lt;https://data.idnau.org/pid/org/78-094-372-050&gt;\n    a sdo:Organization ;\n    sdo:identifier \"78094372 50\"^^id:ausbn ;\n    sdo:name \"Productivity Commission\" ;\n.\n</code></pre> Example: UUID as suffix <pre><code>&lt;https://data.idnau.org/pid/person/34d5d6aa-a5b7-4e3a-91f8-117ffeb474d1&gt;\n    a sdo:Person ;\n    sdo:honorificTitle \"PhD Scholar\" ;\n    dcat:qualifiedRelation [\n    a dcat:Relationship ;\n       dcat:hadRole aarr:memberOf ;\n       sdo:agent &lt;https://data.idnau.org/pid/org/fses&gt; \n    ] ;\n    sdo:url \"https://www.researchgate.net/profile/Sandra-Potter\"^^xsd:anyURI ;\n    sdo:name \"Sandra Potter\" ;\n.\n</code></pre></p>"},{"location":"concepts/agents/patterns/#agent-to-agent-relationships","title":"Agent to agent relationships","text":"<p>how do we describe the relationship between agents?</p> <p>A relationship between agents may be expressed using qualified relations pattern, where <code>dcat:qualifiedRelation</code> indicates a <code>dcat:Relationship</code>.</p> <p>Note</p> <p>The DCAT profile includes patterns for qualified relationships between datasets and agents, and between datasets and other resources, but DCAT does not explicitiy state a pattern for qualified relationships between agents and agents. The the agent to agent pattern in this section follows the DCAT approach with some customaisation.</p> <p>To express a relationship between agents, the <code>dcat:qualifiedRelation</code> property identifies a <code>dcat:Relationship</code>, which is refined with <code>dcat:hadRole</code> and a concept from the Agent to Agent Relationship Roles vocabulary. The object of the statement is expressed as an sdo:agent.</p> <p>Example: Organisation to Organisation relations</p> <pre><code>PREFIX aarr: &lt;https://data.idnau.org/pid/vocab/aarr/&gt;\nPREFIX dcat: &lt;http://www.w3.org/ns/dcat#&gt;\nPREFIX dcterms: &lt;http://purl.org/dc/terms/&gt;\nPREFIX prov: &lt;http://www.w3.org/ns/prov#&gt;\nPREFIX sdo: &lt;https://schema.org/&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n&lt;https://data.idnau.org/pid/org/abs-coatsis&gt;\n    a sdo:Organization ;\n    dcterms:type &lt;https://data.idnau.org/pid/vocab/org-indigeneity/run-by-indigenous-persons&gt; ;\n    sdo:description \"The Centre of Aboriginal and Torres Strait Islander Statistics (CoATSIS) has a leadership and coordination role for national statistical activity about Aboriginal and Torres Strait Islander peoples. They engage with communities across a range of statistical activities and outputs such as the Aboriginal and Torres Strait Islander health and social surveys, the five-yearly Census, administrative data, and data integration projects.\"@en ;\n    dcat:qualifiedRelation [\n       a dcat:Relationship ;\n            dcat:hadRole aarr:partOf ;\n            sdo:agent &lt;https://linked.data.gov.au/org/abs&gt;\n        ] ;\n    sdo:name \"Australian Bureau of Statistics Centre of Aboriginal and Torres Strait Islander Statistics\" ;\n    sdo:url \"https://www.abs.gov.au/about/aboriginal-and-torres-strait-islander-peoples/aboriginal-and-torres-strait-islander-engagement\"^^xsd:anyURI ;\n.\n</code></pre> <p>Example: Person to Organisation relations</p> <pre><code>PREFIX aarr: &lt;https://data.idnau.org/pid/vocab/aarr/&gt;\nPREFIX dcat: &lt;http://www.w3.org/ns/dcat#&gt;\nPREFIX prov: &lt;http://www.w3.org/ns/prov#&gt;\nPREFIX sdo: &lt;https://schema.org/&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n&lt;https://orcid.org/0000-0002-8742-7730&gt;\n    a sdo:Person ;\n    dcterms:type\n        sdo:Person ,\n        &lt;https://data.idnau.org/pid/vocab/org-indigeneity/non-indigenous&gt; ;\n    dcat:qualifiedRelation [\n         a dcat:Relationship ;\n            dcat:hadRole aarr:affiliateOf ;\n            sdo:agent &lt;https://kurrawong.ai&gt;\n        ] ;\n    sdo:email \"nick@kurrawong.ai\"^^xsd:anyURI ;\n    sdo:name \"Nicholas J. Car\"@en ;\n.\n</code></pre> <p>Example: Person to Person relations</p> <pre><code>PREFIX aarr: &lt;https://data.idnau.org/pid/vocab/aarr/&gt;\nPREFIX dcat: &lt;http://www.w3.org/ns/dcat#&gt;\nPREFIX prov: &lt;http://www.w3.org/ns/prov#&gt;\nPREFIX sdo: &lt;https://schema.org/&gt;\n\n&lt;https://orcid.org/0000-0001-5640-3202&gt;\n    a sdo:Person ;\n    dcat:qualifiedRelation [\n       a dcat:Relationship ;\n          dcat:hadRole aarr:proxyOf ;\n          sdo:agent &lt;https://orcid.org/0000-0002-8742-7730&gt;\n    ] ;\n    sdo:name \"Les Kneebone\" ;\n.\n</code></pre>"},{"location":"concepts/agents/patterns/#identifiers","title":"Identifiers","text":"<p>To help identify and disambiguate an agent, indicate an external identifier using <code>sdo:identifier</code> and a code from the Standard Identifiers vocabulary.</p> <pre><code>PREFIX id: &lt;http://id.loc.gov/vocabulary/identifiers/&gt;\nPREFIX sdo: &lt;https://schema.org/&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n# Example: Research Organization Registry (ROR)\n\n&lt;https://linked.data.gov.au/org/und&gt;\n    a sdo:Organization ;\n    sdo:name \"University of Notre Dame\" ;\n    sdo:identifier \"https://ror.org/02stey378\"^^id:ror ;\n.\n\n# Example: Australian Business Number\n\n&lt;https://data.idnau.org/pid/org/28-221-722-606&gt;\n    a sdo:Organization ;\n    sdo:identifier \"28221722606\"^^id:ausbn ;\n    sdo:name \"Yothu Yindi\" ;\n.\n\n# Example: Australian Company Number (ACN)\n\n&lt;https://ror.org/038sjwq14&gt;\n    a sdo:Organization ;\n    sdo:identifier \"633798857\"^^id:auscn ;\n    sdo:name \"Australian Research Data Commons Limited\" ;\n.\n\n# Example: Australian Registered Body Number (ARBN) example\n\n&lt;https://www.wikidata.org/wiki/Q781374&gt;\n    a sdo:Organization ;\n    sdo:identifier \"007498482\"^^id:ausrn ;\n    sdo:name \"Australian Conservation Foundation\" ;\n.\n\n# Example: ORCID\n\n&lt;https://data.idnau.org/pid/person/6b196829-bdf7-44d0-9372-e81b787e8030&gt;\n    a sdo:Person ;\n    sdo:name \"Barbara Glowczewski\" ;\n    sdo:identifier \"https://orcid.org/0000-0002-9629-2516\"^^id:orcid ;\n.\n</code></pre>"},{"location":"concepts/vocabs/creation/","title":"Advanced vocabulary editing","text":"<p>Scope</p> <p>This content is in intended to provide guidance on the creation optional vocabulary elements that will enrich and optimise semantics, provenance and interoperability. </p> <p>Prerequisite</p> <p>It is recommended that Introduction to Vocabularies module is completed prior to Advanced vocabulary editing. Note that some of the exercises in this module will build on changes implemented in the introductory module</p> <p>Outcome</p> <p>On completing this module you will be able to understand and apply an expanded set of properties to vocabulary concepts and concept schemes.</p> <p>\ud83d\udca1 Identifies troubleshooting tips, common errors and potential issues.</p> <p>\ud83d\udcdd Notes that summarise content at the end of a module.</p>"},{"location":"concepts/vocabs/creation/#introduction","title":"Introduction","text":"<p>The Introduction to vocabularies module focused on basic vocabulary properties that are typically required by vocabulary systems and standards. This module will describe more optional properties that will improve the a vocabularies semantics, provenance and interoperability with other vocabularies and with data systems. </p>"},{"location":"concepts/vocabs/creation/#mapping-concepts-with-concepts-in-other-vocabularies","title":"Mapping concepts with concepts in other vocabularies","text":"<p>In the basic structure of a vocabulary, concepts may be related to other concepts via broader, narrower or related properties. We can also relate to a concept to a concept in a different vocabulary. Concept matching across vocabularies is done in a similar way with these properties: Broad match, Narrower match, Related match.</p> <p><code>skos:broadMatch</code> example:</p> <p>Limestone packstone <code>skos:broadMatch</code> Packstone ... where Limestone packstone is a concept in the GSWA rock classification scheme, and Packstone is a concept in the INSPIRE code list register.</p> <p><code>skos:exactMatch</code> example:</p> <p>Child support <code>skos:exactMatch</code> Child support ... where Child support is a concept in both Public Policy Taxonomy and FAST.</p>"},{"location":"concepts/vocabs/creation/#exercise-match-a-concept-with-a-concept-in-another-vocabulary","title":"\ud83d\udea7 Exercise: match a concept with a concept in another vocabulary.","text":"<p>In some cases there may be concepts in a vocabulary that we can reliably say represent the same thing in the world. To promote interoperability between vocabularies (and therefore datasets, catalogues and collections) it's a good idea to 'match' these concepts. </p> <p>\ud83d\udca1 Tip: use a skos match property to reference another skos:concept or to a similar semantic category such as an owl:NamedIndividual. Do not use skos match properties to match to non-semantic resources.</p> <p>In this exercise we will use <code>skos:exactMatch</code> to link \"Animal dispersal\" with the concept \"Zoochory\" from the National Agriculture Library Thesaurus.</p> <ol> <li>Go to VocEdit in Chrome  </li> <li>Project &gt; Open <code>pestRiskPath_training.ttl</code> from your local directory (don't have the file? see the first exercise in Introduction to Vocabularies)  </li> <li>Select Animal dispersal from under Concepts in the left-hand panel  </li> <li>Properties &gt; Add new predicate </li> <li>Add a new predicate &gt; <code>\"http://www.w3.org/2004/02/skos/core#exactMatch\"</code> &gt; Add </li> <li>Properties &gt; exactMatch (the field you just created)  &gt; Add new value by type</li> <li>Add an IRI value &gt; Options (three dots) &gt; Widgets &gt; URIEditor &gt; Add <code>\"https://lod.nal.usda.gov/nalt/332111\"</code> </li> <li>Project &gt; Save</li> </ol> <p>\ud83d\udca1 Tip: strictly speaking you should only use <code>skos:exactMatch</code> when you know that the other vocabulary does, or plans to make a match back to the concept in your vocabulary. Why not get in touch? Notify the external vocabulary managers that you're matching with their vocabulary and you might get matched back!</p> <p>Now let's add a <code>skos:broadMatch</code>. Like <code>skos:broader</code>, the <code>skos:broadMatch</code> property matches a concept with another broader concept that is in a different concept scheme. We will add a skos:broadMatch from \"Wildlife trafficking\" to \"Crime\" in the Centre for Agriculture and Bioscience International (CABI) Thesaurus.</p> <ol> <li>Select Wildlife trafficking from under Concepts in the left-hand panel  </li> <li>Properties &gt; Add new predicate </li> <li>Add a new predicate &gt; <code>\"http://www.w3.org/2004/02/skos/core#broadMatch\"</code> &gt; Add </li> <li>Properties &gt; broadMatch (the field you just created)  </li> <li>Add an IRI value &gt; Options (three dots) &gt; Widgets &gt; URIEditor &gt; Add <code>\"https://id.cabi.org/cabt/33618\"</code> </li> <li>Project &gt; Save </li> </ol>"},{"location":"concepts/vocabs/creation/#images","title":"Images","text":"<p>Associating a <code>skos:concept</code> with an image that illustrates meaning is a powerful and, perhaps obviously, language-neutral way of clarifying the meaning and scope of a concept. There are various different ways of modelling an image reference within a skos vocabulary. The skos model does mention image references within the context of Documentation properties (e.g. <code>skos:example</code>; <code>skos:scopeNote</code>). While using Documentation properties to refer to an image may be syntactically correct, most systems will be expecting textual data in these fields. In the exercise below we will add an image reference using a schema.org property \"Image\".</p> <p>\ud83d\udca1 Tip: There are a number of approaches to adding an image to a vocabulary concept - the exercise below illustrates one valid approach. See other approaches in our Patterns document.</p>"},{"location":"concepts/vocabs/creation/#exercise-add-an-image-to-a-concept","title":"\ud83d\udea7 Exercise: add an image to a concept","text":"<p>We will add an image reference with a URL from Wikipedia Commons to the concept \"Storm water\".</p> <ol> <li>Go to VocEdit in Chrome  </li> <li>Project &gt; Open <code>pestRiskPath_training.ttl</code> from your local directory (don't have the file? see the first exercise in Introduction to Vocabularies)  </li> <li>Select Storm water from under Concepts in the left-hand panel  </li> <li>Add a new predicate &gt; Properties &gt; Add new predicate </li> <li>Add a new predicate &gt; <code>\"https://schema.org/image\"</code> &gt; Add </li> <li>Select Properties - Image (the field you just created)  </li> <li>Select Add an IRI &gt; Add <code>\"https://commons.wikimedia.org/wiki/File:2019-07-29_172052_Rain_in_Berlin.jpg\"</code> </li> <li>Project &gt; Save</li> </ol>"},{"location":"concepts/vocabs/creation/#related-associated-concepts","title":"Related (associated) concepts","text":"<p>SKOS supports non-hierarchical relationships between concepts using <code>skos:related</code> property. This is based on the 'associative relationship' defined in standards such as ISO 25964-1, which states that related terms are \"semantically or conceptually associated to such an extent that the link between the needs to be made explicit... and it is important to do this for concepts that overlap in scope\" (International Organization for Standardization, 2011, p.63)</p>"},{"location":"concepts/vocabs/creation/#notes","title":"Notes","text":"<p>Note fields are available for each concept. A definition, such as found in a glossary, is required by VocPub (AGLDWG, n.d.). A definition is not intended to be an exhaustive treatment of a concept, but rather explains the scope and usage of the concept.</p> <p>A <code>skos:historyNote</code> is a useful property for vocabulary managers to track decisions that have been made about a concept (label changes, new broader relationships). It can also be used to make a statement about the origin of a concept.</p> <p>\ud83d\udca1 Tip: When writing notes, use plain text only and limit paragraph breaks where possible.</p>"},{"location":"concepts/vocabs/creation/#collections","title":"Collections","text":"<p>There may be a need to define a group of concepts within a vocabulary that share certain characteristics. A vocabulary may contain a collection, or even many collections of concepts.</p> <p>Collections are like a non-hierarchical means of gathering Concepts. So for example concepts that are members of a Collection may be from different parts of a vocabulary hierarchy (and not all broader-narrower parts of a hierarchy branch). One use case for collections is to clearly represent concepts that have been 'imported' from another concept scheme. We will look at Collections used in this way in the Vocabulary Reuse module.</p> <p>A <code>skos:collection</code> connects to a <code>skos:concept</code> using the <code>skos:member</code> property.</p>"},{"location":"concepts/vocabs/creation/#identifiers","title":"Identifiers","text":"<p>Each concept must have a unique identifier that can be looked up in an application or on the web. An IRI, or Internationalized Resource Identifier, is a recommended identifier type for vocabulary concepts. </p> <p>IRIs are web page URLs that:</p> <ul> <li>can be used in data to identify things without necessarily resolving to a web page</li> <li>can be managed with domain name ownership</li> <li>allow for a specified range of characters, e.g. non-English alphabets</li> <li>have validation rules similar to web address (URL) rules, e.g. no spaces</li> </ul> <p>An IRI typically follows a pattern such as:</p> <p><code>http:// [vocabulary subdomain] . [authority / domain] . [vocabulary name] . [concept ID]</code></p> <p>Here's a real example from a published vocabulary:</p> <p><code>http://vocabulary.curriculum.edu.au/scot/15326</code></p> <p>... where:</p> <pre><code>_vocabulary_ is a subdomain\n_curriculum.edu.au_ is a managed or owned domain\n_scot_ is an identifier for the whole vocabulary, and\n_15326_ is a concept ID\n</code></pre>"},{"location":"concepts/vocabs/creation/#iri-patterns","title":"IRI patterns","text":"<p>What is the name of the concept above that has 15326 as an identifier? You need to look it up on the web! The whole point of using <code>http</code> identifiers is so that the concepts can be looked up on the web by anyone, anywhere (and by anything - humans, browsers, bots etc.).</p> <p>Note that this IRI uses an increment method for generating a concept ID - the next concept IRI added to this vocabulary would have the suffix 15327. This incremented number doesn't mean anything - we can't tell what the concept is about just by looking at this number. Any vocabulary could use this same increment method, and therefore this ID would appear for concepts in different vocabularies. The IRI as a whole, however, is unique.</p> <p>Here's another method for generating an IRI suffix:</p> <p><code>http://vocabulary.curriculum.edu.au/crossCurriculum/f7f47140-a85e-498b-9367-0d468082fc2b</code></p> <p>The suffix here is a UUID, or a Universally Unique Identifier. Note that if we took the UUID out of context (away from the whole IRI), we could consider it to be unique on its own terms - UUIDs are designed that way. </p> <p>Tip: UUID are not registered and can be generated by anyone using online tools.</p> <p>A third NOT RECOMMENDED method for constructing a concept ID is to base the ID on whatever <code>prefLabel</code> has been chosen. This has the advantage of making the IRI itself readable and understandable by humans - but there are several disadvantages also and the preferred label method should be avoided if possible.</p> <p><code>https://data.idnau.org/pid/vocab/org-indigeneity/run-by-indigenous-persons</code></p> <p>... where: \"/org-indigeneity/\" is the ID for the vocabulary, and \"/run-by-indigenous-persons/\" is the ID for the concept</p> <p>The prefLabel method is not recommended. Why? What if the prefLabel for this concept changes to \"Managed by indigenous persons\"? The IRI stays the same (they should be persistent), and now doesn't match (exactly) the <code>prefLabel</code>. A similar problem is encountered if the concept has multiple <code>prefLabel</code> in different languages - which one should be used? IRIs are more robust if their concept IDs are opaque (they don't say anything about the concept itself).</p>"},{"location":"concepts/vocabs/creation/#version-iri","title":"Version IRI","text":"<p>A supplementary IRI may be added that indicates the version of a concept, e.g. \"1.1\". A version IRI may be used, example:</p> <pre><code>@prefix skos: &lt;http://www.w3.org/2004/02/skos/core#&gt; .\n@prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; .\n\nIRI: https://linked.data.gov.au/def/address-alias-type\nskos:prefLabel: Address Alias Type\nowl:VersionIRI: https://linked.data.gov.au/def/address-alias-type/1.0\n</code></pre>"},{"location":"concepts/vocabs/creation/#references-and-further-reading","title":"References and Further Reading","text":"<ul> <li>AGLDWG. (n.d.). VocPub profile specification. Retrieved April 17, 2025, from https://linked.data.gov.au/def/vocpub</li> <li>International Organization for Standardization. (2011). Information and documentation \u2014 Thesauri and interoperability with other vocabularies \u2014 Part 1: Thesauri for information retrieval (ISO Standard No. 25964-1:2011). https://www.iso.org/standard/53657.html</li> <li>W3C (n.d.). QSKOS. Retrieved March 5, 2025, from https://www.w3.org/2001/sw/wiki/QSKOS</li> <li>W3C (2009). SKOS reference. https://www.w3.org/TR/skos-reference/</li> <li>W3C (2014). Turtle: Terse RDF triple language (W3C Recommendation). Retrieved from https://www.w3.org/TR/turtle/</li> </ul>"},{"location":"concepts/vocabs/introduction/","title":"Introduction to Vocabularies","text":"<p>Scope</p> <p>This module is in intended to introduce vocabularies and to provide initial steps and guidance on starting a vocabulary with minimum elements. This module will also explain the rationale for vocabularies within the context of Knowledge Graph data management.</p> <p>Audience</p> <p>The content is primarily targeted to managers and users (vocab owners and contributors) of established vocabularies. It is assumed that learners have some experience with using document management or version control systems, and general familiarity with data management in practice.</p> <p>Outcome</p> <p>These modules are intended to provide an introduction to vocabulary creation and management, and provide initial guidance on best practice for administration and management of vocabularies within part of broader data management systems. It is recommended that users independently access other resources (see references here), as part of ongoing independent learning.</p> <p>\ud83d\udca1 Identifies troubleshooting tips, common errors and potential issues.</p>"},{"location":"concepts/vocabs/introduction/#exercises","title":"\ud83d\udea7 Exercises","text":""},{"location":"concepts/vocabs/introduction/#an-introduction-to-vocabularies","title":"An Introduction to Vocabularies","text":"<p>As languages speakers, we have developed the categorization of \"things\" as a means to both understand and communicate our experience of the world. The sheer volume of data that we interact with has necessitated approaches to using our shared understanding of language and naming. Particularly when using information as part of large-scale data holdings, it can be beneficial to encourage consistency through the use of controlled vocabularies.</p> <p>When sharing information across diverse groups of people (or perhaps software applications), there is need for a common understanding of exactly what is being referred to. This is where controlled vocabularies provide a structure from which terminology applied to information can be driven from an agreed stated understanding of that concept. That understanding can be a definition for human understanding, or a machine-readable unique identifier for machine processing.</p> <p>Whatever size and shape, the vocabularies mentioned in these modules are designed for describing data and content. Vocabularies can be used to describe (or catalogue) content in information systems. Vocabularies can also optimise search engines and provide the basis for navigation in information systems, making it easier for users to find content and data.</p>"},{"location":"concepts/vocabs/introduction/#vocabulary-types","title":"Vocabulary types","text":"<p>In this section we will introduce some common vocabulary types. By introducing simple and more complex vocabulary examples we will introduce some important vocabulary features.</p>"},{"location":"concepts/vocabs/introduction/#glossary","title":"Glossary","text":"<p>... defining terms</p> <p>Glossary are a very common form of vocabulary found in many print and web resources. A glossary is a list of concepts, expressed by natural language terms (we will refer to terms and labels interchangeably) with added definitions.</p> <p></p> <p>Each concept in a Glossary has at least one label and one definition. Some glossaries include see references that direct a user to a preferred term. This equivalence mapping is a common feature in more complex vocabulary types such as in a thesaurus that we will look at below. But first we will look at vocabularies that include hierarchy relationships.</p>"},{"location":"concepts/vocabs/introduction/#taxonomies","title":"Taxonomies","text":"<p>... a very short history</p> <p>Taxonomies are vocabularies with hierarchical relationships between concepts. Conventionally, we might say that concept A is broader than concept B, when the all-some rule apples: All B's are A, and some A's are B. For example, all apples are fruit, and some fruit are applies. Therefore, fruit is broader than apples.</p> <p>Modern taxonomies that are used to organise and retrieve data owe their heritage to two disciplines: biology, or the taxonomy of living things, featuring familiar concepts of class, family, genus, species etc..., and financial classifications, where concepts are typically categorised as either function, activity of transaction.</p> <p><pre><code>%% Title: **Financial classification**\ngraph TD\nsubgraph \"Financial classification\"\n    F[Function]\n    T1[Transaction A]\n    T2[Transaction B]\n    A1[Activity 1]\n    A2[Activity 2]\n    A3[Activity 3]\n\n    F --&gt; T1\n    F --&gt; T2\n    T1 --&gt; A1\n    T1 --&gt; A2\n    T2 --&gt; A3\nend</code></pre> The definition, or meaning of a given term is given, in part, by its relationship to broader and narrower terms. For example, we have a clearer understanding of what crane means if it has a broader relationship with birds (and not construction equipment).</p> <p></p> <pre><code>%% Title: Taxonomy of living things\ngraph TD\nsubgraph \"Taxonomy of living things\"\n    F[Family]\n    G1[Genus A]\n    G2[Genus B]\n    S1[Species 1]\n    S2[Species 2]\n    S3[Species 3]\n\n    F --&gt; G1\n    F --&gt; G2\n    G1 --&gt; S1\n    G1 --&gt; S2\n    G2 --&gt; S3\nend\n    classDef green fill:#90ee90,stroke:#333,stroke-width:2px;\nclass F,G1,G2,S1,S2,S3 green;</code></pre> <p>We will see below in Vocabularies in the context of knowledge graphs how the broader / narrower relationship between concepts can improve search and extraction functions in data where vocabularies are used to enrich data. </p>"},{"location":"concepts/vocabs/introduction/#thesaurus","title":"Thesaurus","text":"<p>... a (more) complete picture</p> <p>The modern retrieval thesaurus combines the structure of a taxonomy with an additional non-hierarchical relationship and also synonym control. Thesauri establish hierarchy, association and equivalence between terms. Each can be expressed using the Simple Knowledge Organization System (SKOS) properties <code>skos:broader</code> / <code>skos:narrower</code>; <code>skos:relation</code>; and <code>skos:prefLabel</code> / <code>skos:altLabel</code> (W3C, 2009).</p> <pre><code>graph TD\n    A[Concept A] \n    B[Concept B]\n    C[Concept C]\n    D[Concept D]\n    S[Synonym of A]\n\n    %% Broader / Narrower relationships\n    A -- \"skos:narrower\" --&gt; B\n    B -- \"skos:broader\" --&gt; A\n\n    %% Associative (related) relationship\n    A &lt;-- \"skos:related\" --&gt; C\n\n    %% Synonym relationship (using skos:altLabel)\n    A -- \"skos:altLabel\" --&gt; S\n\n\n    %% Additional hierarchical relationship for illustration\n    C -- \"skos:narrower\" --&gt; D\n    D -- \"skos:broader\" --&gt; C</code></pre> <p>\ud83d\udca1 Tip: the <code>skos:related</code> property is most useful for relating disparate concepts in deep, complex hierarchies. Use <code>skos:related</code> sparingly - don't relate everything to everything! </p> <p>We will look at SKOS properties in more detail in the Properties section.</p>"},{"location":"concepts/vocabs/introduction/#vocabularies-in-knowledge-graphs","title":"Vocabularies in knowledge graphs","text":"<p>Thought of as an interconnected system of data classes, a knowledge graphs may involve vocabularies as an additional class that will connect with some or all other classes. In a knowledge graph, a vocabulary concept can be modelled as just another class. </p> <p>One function that vocabularies serve is to supplement and fill semantic gaps in data relations. In the example below, classes A, B an C are each related to each other in some way. Class D is not related to other classes. A concept from a vocabulary is also included, and has relationships to classes A, B and C.</p> <pre><code>graph LR;\n    classDef concept fill:#f9f1a5,stroke:#b59a00;\n    classDef default fill:#dae8fc,stroke:#6c8ebf;\n\n    4[\"CLASS C\"];\n    7[\"CONCEPT A\"]:::concept;\n    8[\"CLASS B\"];\n    9[\"CLASS A\"];\n    10[\"CLASS D\"];\n\n    4 -- \"relation\" --&gt; 7;\n    4 -- \"relation\" --&gt; 8;\n    8 -- \"relation\" --&gt; 7;\n    9 -- \"relation\" --&gt; 7;\n    9 -- \"relation\" --&gt; 8;</code></pre> <p>The relationships between classes and concepts is often of a subject nature - that is to say the class instance is about the concept.</p> <pre><code>graph LR;\n    classDef concept fill:#f9f1a5,stroke:#b59a00;\n    classDef default fill:#dae8fc,stroke:#6c8ebf;\n\n    4[\"CLASS C\"];\n    7[\"CONCEPT A\"]:::concept;\n    8[\"CLASS B\"];\n    9[\"CLASS A\"];\n    10[\"CLASS D\"];\n\n    4 -- \"subject\" --&gt; 7;\n    4 -- \"relation\" --&gt; 8;\n    8 -- \"subject\" --&gt; 7;\n    9 -- \"subject\" --&gt; 7;\n    9 -- \"relation\" --&gt; 8;</code></pre> <p>Now we will look at a domain example using possible interrelationships between spatial data classes, focusing on roads.</p> <pre><code>graph LR;\n    classDef concept fill:#f9f1a5,stroke:#b59a00;\n    classDef default fill:#dae8fc,stroke:#6c8ebf;\n\n    4[\"Road types\"];\n    7[\"One Way\"]:::concept;\n    8[\"Maintainers\"];\n    9[\"Lane counts\"];\n    10[\"Seasonality\"];\n\n    4 -- \"subject\" --&gt; 7;\n    4 -- \"relation\" --&gt; 8;\n    8 -- \"subject\" --&gt; 7;\n    9 -- \"subject\" --&gt; 7;\n    9 -- \"relation\" --&gt; 8;</code></pre> <p>The concept <code>One Way</code> comes from <code>Road directions</code> vocabulary, where the concept <code>One Way From To</code> may be defined as a <code>skos:narrower</code> concept.</p> <pre><code>graph LR;\n    classDef concept fill:#f9f1a5,stroke:#b59a00;\n    classDef default fill:#dae8fc,stroke:#6c8ebf;\n\n    4[\"Road types\"];\n    7[\"One Way\"]:::concept;\n    8[\"Maintainers\"];\n    9[\"Lane counts\"];\n    10[\"Seasonality\"];\n    11[\"One Way From To\"]:::concept;\n\n    4 -- \"subject\" --&gt; 7;\n    4 -- \"relation\" --&gt; 8;\n    8 -- \"subject\" --&gt; 7;\n    9 -- \"subject\" --&gt; 7;\n    9 -- \"relation\" --&gt; 8;\n    7 -- \"narrower\" --&gt; 11;</code></pre> <p>Let's assume that the <code>Seasonality</code> class contains data profiled with the <code>One Way From To</code> directional roads concepts. So there is also a relationship with the <code>skos:narrower</code> concept provided in the vocabulary. This hierarchy relationship in the vocabulary then provides a bridge between classes of information.</p> <pre><code>graph LR;\n    classDef concept fill:#f9f1a5,stroke:#b59a00;\n    classDef default fill:#dae8fc,stroke:#6c8ebf;\n\n    4[\"Road types\"];\n    7[\"One Way\"]:::concept;\n    8[\"Maintainers\"];\n    9[\"Lane counts\"];\n    10[\"Seasonality\"];\n    11[\"One Way From To\"]:::concept;\n\n    4 -- \"subject\" --&gt; 7;\n    4 -- \"relation\" --&gt; 8;\n    8 -- \"subject\" --&gt; 7;\n    9 -- \"subject\" --&gt; 7;\n    9 -- \"relation\" --&gt; 8;\n    7 -- \"narrower\" --&gt; 11;\n    10 -- \"subject\" --&gt; 11;</code></pre> <p>Because of this relation between concepts in the vocabulary, it's possible to make an inference that connects classes that were previously unrelated, such as between <code>Lane counts</code> data and <code>Seasonality</code> data.</p> <p><pre><code>graph LR;\n    classDef concept fill:#f9f1a5,stroke:#b59a00;\n    classDef default fill:#dae8fc,stroke:#6c8ebf;\n\n    4[\"Road types\"];\n    7[\"One Way\"]:::concept;\n    8[\"Maintainers\"];\n    9[\"Lane counts\"];\n    10[\"Seasonality\"];\n    11[\"One Way From To\"]:::concept;\n\n    4 -- \"subject\" --&gt; 7;\n    4 -- \"relation\" --&gt; 8;\n    8 -- \"subject\" --&gt; 7;\n    9 -- \"subject\" --&gt; 7;\n    9 -- \"relation\" --&gt; 8;\n    7 -- \"narrower\" --&gt; 11;\n    10 -- \"subject\" --&gt; 11;\n    9 -. \"relation\" .-&gt; 10;</code></pre> Let's put this into a narrative form:</p> <p>We know that some roads are closed on a seasonal basis, but we don't know what portion of these are one lane roads. But we do have data about the seasonality of 'One Way From Two' roads, also called 'One way with vector' roads. Because these roads are defined as a type of One Way road (defined as <code>skos:narrower</code>), we can infer information about seasonal road closures for one lane roads.</p>"},{"location":"concepts/vocabs/introduction/#vocabulary-properties","title":"Vocabulary properties","text":"<p>Vocabularies contain, as a minimum: preferred labels, definitions and identifiers</p> <p>We have already introduced concepts and their relation properties to other concepts. In this section we will look at more concept properties, including properties that are required for validation in vocabulary quality standards.</p>"},{"location":"concepts/vocabs/introduction/#minimum-properties-preflabel-definition-and-identifier","title":"Minimum properties: prefLabel, definition and identifier","text":"<p>To comply with VocPub profile (AGLDWG, n.d.), each concept must have at least:</p> <ul> <li>a <code>skos:prefLabel</code> which is the main way that we say and understand the concept;</li> <li>a <code>skos:definition</code> - a short note that describes the concept;</li> <li>an Identifier - a unique way of distinguishing the concept from other concepts</li> </ul>"},{"location":"concepts/vocabs/introduction/#exercise-0pen-edit-and-save-a-vocabulary","title":"\ud83d\udea7 Exercise: 0pen, edit and save a vocabulary","text":"<p>These modules will include a number of editing exercises that use the VocEdit tool and the Pest Risk Pathway vocabulary (PRP). The PRP is an un-published vocabulary, hosted by Kurrawong.ai for training and testing purposes. In this exercise we will add a new concept; a concept preferred label; a concept definition; and a concept identifier.</p> <p>\ud83d\udca1 Chrome browser is needed to use the VocEdit tool.</p> <ol> <li>Go to Download TTL (Right-click and choose \u201cSave link as...\u201d to download)</li> <li>Save the file to your local directory  </li> <li>Open Chrome (if not already)  </li> <li>Go to VocEdit </li> <li>Select Project &gt; Open &gt; Local file</li> <li>Select pestRiskPath_training.ttl from your local directory  </li> <li>Select Resource &gt; Create new</li> <li>Resource type &gt; Concept</li> <li>Add http://example.com/pestRiskPath/</li> <li>Open a new tab and go to UUID Generator </li> <li>Copy the UUID  </li> <li>Paste the UUID in the IRI field and after the stem http://example.com/pestRiskPath/. So the full IRI should look be: http://example.com/pestRiskPath/[UUID]</li> <li>Select Create </li> <li>Edit &gt; prefLabel &gt; \"+\" &gt; Literal string with language</li> <li>Add Wind dispersal</li> <li>In Lang box, Add* \"en\"</li> <li>definition &gt; Add a literal with language </li> <li>Add Dispersal of pests by wind</li> <li>In Lang box, Add* \"en\"</li> <li>Concept scheme relationships - topConceptOf &gt; Select \"+\" &gt; IRI</li> <li>Select a value &gt; select pestRiskPath</li> <li>Save</li> </ol> <p>The pestRiskPathway.ttl will now be updated in your local directory, with the new concept \"Wind dispersal\" added.</p>"},{"location":"concepts/vocabs/introduction/#broader-narrower","title":"Broader / Narrower","text":"<p>We have already introduced the <code>skos:broader</code> and <code>skos:narrower</code> relationships in the sections above on taxonomies and thesaurus vocabularies. </p> <p>Depending on the type and complexity of a vocabulary, there may be a requirement that all concepts are related to another concept via <code>skos:broader</code> property. In a taxonomy or thesaurus vocabulary project, a concept that does not have a skos:broader concept may be considered an orphan, unless it is a <code>topConcept</code>. As far as the SKOS standard is concerned, there is no need for all (or any) concepts to be arranged in a hierarchy. In some cases a vocabulary will be mostly flat with selected concepts in narrower relationships to broader concepts.</p> <p>If a <code>skos:Concept</code> does not have a <code>skos:broader</code> property, the VocPub profile requires that it must reference the relevant <code>skos:ConceptScheme</code> IRI with the <code>skos:topConcept</code> property. </p> <p>Tip: Broader and narrower relationships are reciprocal - that is, if A is broader than B, then B is narrower than A. For example:</p> <ul> <li>Dynamic land cover <code>broader</code> Land cover and land use</li> <li> <p>Land cover and land use <code>narrower</code> Dynamic land cover</p> </li> <li> <p>Apples <code>broader</code> Pomme fruit</p> </li> <li> <p>Pomme fruit <code>narrower</code> Apples</p> </li> <li> <p>Hospitals <code>narrower</code> Private hospitals</p> </li> <li>Private hospitals <code>broader</code> Hospitals</li> </ul> <p>Arranging concepts into a hierarchy supports discovery via:</p> <ul> <li>Search expansion - a search system can add results that match narrower concepts of a search term. For example a search for Granitoid would return resources about granitoid OR granite</li> <li>Navigation - top-down navigation or breadcrumb links can be launched in an interface using broader/narrower relationships. For example, clicking on Pomme fruit launches a list of links to apples, pears and quinces</li> </ul> <p>In a vocabulary, it's possible to keep adding narrower relationships by creating more and more specific concepts. For example, a catalogue that is about horticulture probably needs a vocabulary with more specific (narrower) concepts than just apples (e.g. Kiku Fuji).</p> <p>\ud83d\udca1 Tip: Only add narrower concepts that you would expect to be used to describe content in a catalogue, and distinguish that content from others, with that concept. Don't make a vocabulary hierarchy very deep with specific concepts just because you can!</p>"},{"location":"concepts/vocabs/introduction/#exercise-add-broader-concept-relations","title":"\ud83d\udea7 Exercise: add broader concept relations","text":"<p>In this exercise we will add a broader relationship between two concepts. Note that once a concept has a broader relationship, it can no longer be regarded as a 'top concept' and we will remove the top concept statement accordingly.</p> <ol> <li>Go to VocEdit in Chrome  </li> <li>Project &gt; Open <code>pestRiskPath_training.ttl</code> from your local directory  </li> <li>Select Spore dispersal from the left-hand list of concepts  </li> <li>Concept relationships &gt; Broader &gt; Add a new value &gt; IRI</li> <li>From the Select a value dropdown, search for or select Host plants &gt; select</li> <li>Save</li> </ol> <p>This change optimises the SKOS model by applying a broader relationship between concepts that are conceptually broader and narrower. In a retrieval system we might expect a query for datasets about host plants as pest vectors to return a resource about Spore dispersal. The <code>skos:broader</code> relation support such an inference.</p>"},{"location":"concepts/vocabs/introduction/#alternative-labels","title":"Alternative labels","text":"<p>Each concept must have at least one Preferred label (<code>skos:prefLabel</code>), based on the word or phrase that best describes the concept. We often use different terms to mean the same thing - the <code>skos:prefLabel</code> should be the term that is used most frequently, or understood and used by most expected users of a system or catalogue.</p> <p>In addition, each concept may have one ore more Alternate labels (<code>skos:altLabel</code>). It's a good idea to add one or more <code>altLabel</code> to a concept so that it can be found in different ways. A concept can have any number of alternate labels, provided they are similar enough to the common understanding of the concept.</p> <p>\ud83d\udca1 Tip: when adding a <code>skos:altLabel</code>, ask this question: If I searched with a preferred label, and found some information matching an alternative label in the text, would I be satisfied by the search result?</p> <p>Here are some common scenarios where we might need to choose between preferred and alternative labels:</p>"},{"location":"concepts/vocabs/introduction/#common-vs-scientific-terms","title":"Common vs Scientific terms","text":"<p>Connect scientific or technical names with common names. For example:</p> <ul> <li>Red imported fire ant <code>skos:altLabel</code> Solenopsis invicta</li> <li>Boghead Coal <code>skos:altLabel</code> Torbanite</li> <li>Spore dispersal <code>skos:altLabel</code> Sporulation</li> </ul>"},{"location":"concepts/vocabs/introduction/#superseded-terms","title":"Superseded terms","text":"<p>Even if a term is no longer used in recent content, users may still search a catalogue using superseded language. Storing superseded terms as alternative labels helps to group content that contains antiquated language with content written in current language. For example:</p> <ul> <li>Aeolian Sand <code>skos:altLabel</code> Eskimo Sand</li> <li>Utility hole <code>skos:altLabel</code> Manhole</li> </ul>"},{"location":"concepts/vocabs/introduction/#acronyms-vs-phrases","title":"Acronyms vs phrases","text":"<p>In general, an acronym or initialism should be managed as an <code>skos:altLabel</code>; example: </p> <ul> <li>Greenhouse gasses <code>skos:altLabel</code> GHG </li> </ul> <p>An exception is when the acronym is better known or more frequently used. For example:</p> <ul> <li>TNT <code>skos:altLabel</code> Trinitrotoluene</li> <li>CSIRO <code>skos:altLabel</code> Commonwealth Scientific and Industrial Research Organisation</li> </ul>"},{"location":"concepts/vocabs/introduction/#official-vs-common-language","title":"Official vs common language","text":"<p>Use an <code>altLabel</code> to connect official or technical language with natural language. For example:</p> <ul> <li>Bi-directional <code>skos:altLabel</code> Two way</li> <li>Alcohol-impaired driving <code>skos:altLabel</code> Drink-driving</li> </ul>"},{"location":"concepts/vocabs/introduction/#exercise-add-alternative-labels","title":"\ud83d\udea7 Exercise: add alternative labels","text":"<p>In this exercise we will add an alternative label to a concept. </p> <p>\ud83d\udca1 Tip: You will need to first add the <code>skos:altLabel</code> property to VocEdit as it is not required by VocPub.</p> <ol> <li>Go to VocEdit in Chrome  </li> <li>Project &gt; Open <code>pestRiskPath_training.ttl</code> from your local directory  </li> <li>Select Spore dispersal from the left-hand list of concepts  </li> <li>Other Properties &gt; Add property </li> <li>Add http://www.w3.org/2004/02/skos/core#altLabel &gt; Add property </li> <li>in the altLabel field you just created &gt; \"+\" &gt; Add new value &gt; Literal with language</li> <li>Add Sporulation</li> <li>Add \"en\" to lang field</li> <li>Save</li> </ol>"},{"location":"concepts/vocabs/introduction/#top-concepts","title":"Top Concepts","text":"<p>If a <code>skos:Concept</code> does not have a <code>skos:narrower</code> relationship, it is automatically assumed to be a <code>skos:topConceptOf</code> a <code>skos:ConceptScheme</code> and must be declared as such.</p> <p>A concept may be moved out of the </p>"},{"location":"concepts/vocabs/introduction/#concept-scheme","title":"Concept Scheme","text":"<p>A Concept Scheme is some metadata about the vocabulary as a whole - the vocabulary title (<code>skos:prefLabel</code>), a definition (<code>skos:definition</code>), and a unique identifier are minimum requirements. All vocabularies must have a Concept Scheme, and it should include:</p> <ul> <li> <p>an Identifier - create an IRI following the same pattern as the IRIs for concepts. For the suffix, instead of a concept ID, add a Concept scheme ID. This may be the name of the Concept scheme (the vocabulary), e.g.: - <code>https://linked.data.gov.au/def/road-types</code>   ... where Road types is the name of the concept scheme.</p> </li> <li> <p>a Preferred label - the same property that is used for a Concept. Use a Preferred label for the name or title of the vocabulary (this may also be used for the Concept Scheme ID)</p> </li> <li>a Definition - a definition of the Concept Scheme. Use plain text only but paragraphs may be separated by newlines. Also used for Concepts</li> <li>a Created date. When the Concept Scheme was first created. This might be automatically created by a vocabulary editor</li> <li>a History note - a note on the origin or history of a vocabulary - such as how or from what it was generated.</li> </ul>"},{"location":"concepts/vocabs/introduction/#exercise-edit-a-concept-scheme","title":"\ud83d\udea7 Exercise: edit a concept scheme","text":"<p>We will continue to edit the Pest Risk Pathway vocabulary, but this time we will edit the concept scheme which is the metadata about the vocabulary as a whole.</p> <ol> <li>Go to VocEdit in Chrome    </li> <li>Project &gt; Open <code>pestRiskPath.ttl</code> from your local directory  </li> <li>Select Pest Risk Pathway from under Vocabularies in the left-hand panel  </li> <li>Annotations &gt; definition &gt; \"+\" &gt; Add a new value &gt; literal with language </li> <li>Add A vocabulary describing various structures, modes and activities that introduce unwanted pests, weeds and diseases.</li> <li>Add \"en\" to lang field</li> <li>Save</li> </ol>"},{"location":"concepts/vocabs/introduction/#summary","title":"Summary","text":"<p>In this module we have introduced vocabularies - different types and how they are useful. We have also used a vocabulary editing tool to create the minimum elements for a concept and a concept scheme. </p>"},{"location":"concepts/vocabs/introduction/#references-and-further-reading","title":"References and Further Reading","text":"<ul> <li>AGLDWG. (n.d.). VocPub profile specification. Retrieved April 17, 2025, from https://linked.data.gov.au/def/vocpub</li> <li>W3C (n.d.). QSKOS. Retrieved March 5, 2025, from https://www.w3.org/2001/sw/wiki/QSKOS</li> <li>W3C (2009). SKOS reference. https://www.w3.org/TR/skos-reference/</li> <li>W3C (2014). Turtle: Terse RDF triple language (W3C Recommendation). Retrieved from https://www.w3.org/TR/turtle/</li> </ul>"},{"location":"concepts/vocabs/patterns/","title":"Vocabulary Patterns","text":"<p>Scope</p> <p>This content is in intended to convey Best Practice patterns in vocabulary content</p> <p>Audience</p> <p>Technical vocabulary creators.</p> <p>All the patterns documented here assume the use of the SKOS data model for vocabulary content and Semantic Web methods for data management and access. </p> <p>Outcome</p> <p>Technical vocabulary creators should learn both what KurrawongAI considers to be Best Practice for certain aspects of vocabulary content and also how KurrawongAI and other vocabulary creation and publication tools support the pattern.</p>"},{"location":"concepts/vocabs/patterns/#images","title":"Images","text":"<p>Can we use images for concepts in vocabularies?</p>"},{"location":"concepts/vocabs/patterns/#context","title":"Context","text":"<p>Some vocabularies lend themselves to the use of images to either define or explain the concepts they contain. For example, a vocabulary about road signs really should show images of the sign, not just describe them. Other vocabularies might like to exemplify concepts with images.</p>"},{"location":"concepts/vocabs/patterns/#solution","title":"Solution","text":"<p>Yes we can use images with the following clarifications:</p> <ol> <li>there is more than one way</li> <li>different approaches require different system capabilities for authoring or displaying vocabs</li> </ol>"},{"location":"concepts/vocabs/patterns/#conceptual-handling","title":"Conceptual handling","text":"<p>Conceptually, we just link an image to a Concept within a vocab using an appropriate predicate. The SKOS Reference document's Notes section indicates that certain note predicates such as <code>skos:example</code> might be appropriate since the don't only have to be used with text, even though they usually are.</p> <p>Note</p> <p>If a Concept is actually defined by an image, it may seem appropriate to link directly to the image using the <code>skos:definition</code> predicated but we advise against this as it may be invalid for certain vocabulary profiles such as VocPub and may be hard for systems to implement. Instead use another predicate and describe how the image, indicated by the chosen predicate, is the defining part of the Concept in the definition field, in text. </p> <p>We can also choose to use a non-SKOS predicate, especially common ones used for images, such as <code>schema:image</code>. This would allow the use of regular SKOS predicates, such as <code>skos:definition</code>, <code>skos:example</code> etc. for their common use and the image predicate is an extra.</p> <p>The information about the images actually linked to by <code>skos:example</code> or <code>schema:image</code> can be one of the following:</p> <ul> <li>a web address - URL<ul> <li>e.g. <code>https://upload.wikimedia.org/wikipedia/commons/4/4c/2019-07-29_172052_Rain_in_Berlin.jpg</code> - a publicly available image on WikiMedia</li> </ul> </li> <li>a local file path<ul> <li>e.g. <code>images/germany/rain_in_berlin.jpg</code> - only available on a particular system</li> </ul> </li> <li>embedded image content<ul> <li>e.g. an SVG image defined in XML text</li> <li>e.g. a hex-encoded raster image, like a JPG</li> </ul> </li> <li>a Blank Node describing an image</li> </ul> <p>There are pros and cons to each type of information listed above. </p> <p>A web address is easy to record - just a predicate like <code>schema:image</code> pointing to the URL - but it will break if the image disappears offline, so the vocabulary has a dependency on the image's stability to keep working.</p> <p>A local file path will only work if any tool publishing the vocabulary can access and on-deliver (render) the image.</p> <p>An embedded image stays within the vocab's source data file, which means it can't ever be lost, but could be large: the JPG image linked to in the web address bullet above is 7.5MB as a JPEG but 137MB when converted to HEX which is a form of text encoding that can be used in an RDF file. This may only be appropriate for small vector images such as icons of map symbols.</p> <p>If we want to provide more information about the image than either just its embedded content or a link to its location, we can qualify it by linking to a Blank Node from which we can then link to remote content via a URL or local file path or to embedded content. From the same Blank Node, we can then also link to other information such as captions, copyright info, etc. See Examples below.</p>"},{"location":"concepts/vocabs/patterns/#examples","title":"Examples","text":""},{"location":"concepts/vocabs/patterns/#url-using-schemaimage","title":"URL using <code>schema:image</code>","text":"<pre><code>PREFIX schema: &lt;https://schema.org/&gt;\nPREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n:dog\n  a skos:Concept ;\n  skos:prefLabel \"Dog\"@en ;\n  skos:altLabel \"Domestic Dog\"@en ;\n  skos:definition \"The dog (Canis familiaris or Canis lupus familiaris) is a domesticated descendant of the gray wolf.\"@en ;\n  schema:image \"https://en.wikipedia.org/wiki/Dog#/media/File:Chin_posing.jpg\" ;\n.\n</code></pre> <p>Note here the use of <code>xsd:anyURI</code> for a typed literal for the image link, as opposed to an IRI named node, which would be <code>&lt;https://en.wikipedia.org/wiki/Dog#/media/File:Chin_posing.jpg&gt;</code>. This is because the image is not part of the vocab's graph (the nodes in its data) but a link off to somewhere else.</p>"},{"location":"concepts/vocabs/patterns/#local-file-path-using-skosexample","title":"Local file path using <code>skos:example</code>","text":"<pre><code>PREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n:dog\n  a skos:Concept ;\n  skos:prefLabel \"Dog\"@en ;\n  skos:altLabel \"Domestic Dog\"@en ;\n  skos:definition \"The dog (Canis familiaris or Canis lupus familiaris) is a domesticated descendant of the gray wolf.\"@en ;\n  skos:example \"src/img/my_dog.jpg\" ;\n.\n</code></pre>"},{"location":"concepts/vocabs/patterns/#embedded-svg-image","title":"Embedded SVG image","text":"<pre><code>PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;\nPREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n:apron\n    a skos:Concept ;\n    skos:prefLabel \"Apron\"@en ;\n    skos:definition \"An apron, in geology, is a fan-like accumulation of sediments that spreads outward from the base of a slope, such as the edge of a continental shelf, a submarine mountain, or an island. It's typically formed by gravity-driven processes like submarine landslides, debris flows, or turbidity currents.\"@en  ;\n    schema:image \"\"\"&lt;svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:inkscape=\"http://www.inkscape.org/namespaces/inkscape\" xmlns:sodipodi=\"http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd\" xmlns:svg=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"97.118958mm\" height=\"74.286232mm\" viewBox=\"0 0 97.118957 74.286232\" version=\"1.1\" id=\"svg5\" xml:space=\"preserve\" inkscape:version=\"1.2.2 (b0a8486, 2022-12-01)\" sodipodi:docname=\"apron.inkscape.svg\" inkscape:export-filename=\"apron.png\" inkscape:export-xdpi=\"96\" inkscape:export-ydpi=\"96\"&gt;&lt;sodipodi:namedview id=\"namedview7\" pagecolor=\"#ffffff\" bordercolor=\"#666666\" borderopacity=\"1.0\" inkscape:showpageshadow=\"2\" inkscape:pageopacity=\"1\" inkscape:pagecheckerboard=\"0\" inkscape:deskcolor=\"#ffffff\" inkscape:document-units=\"mm\" showgrid=\"false\" inkscape:zoom=\"1.8380915\" inkscape:cx=\"75.077873\" inkscape:cy=\"204.01596\" inkscape:window-width=\"2063\" inkscape:window-height=\"1210\" inkscape:window-x=\"133\" inkscape:window-y=\"70\" inkscape:window-maximized=\"0\" inkscape:current-layer=\"layer1\" /&gt;&lt;defs id=\"defs2\"&gt;&lt;linearGradient inkscape:collect=\"always\" id=\"linearGradient3584\"&gt;&lt;stop style=\"stop-color:#808080;stop-opacity:1;\" offset=\"0\" id=\"stop3580\" /&gt;&lt;stop style=\"stop-color:#808080;stop-opacity:0;\" offset=\"1\" id=\"stop3582\" /&gt;&lt;/linearGradient&gt;&lt;linearGradient inkscape:collect=\"always\" id=\"linearGradient3522\"&gt;&lt;stop style=\"stop-color:#ffffff;stop-opacity:1;\" offset=\"0\" id=\"stop3518\" /&gt;&lt;stop style=\"stop-color:#ffffff;stop-opacity:0;\" offset=\"1\" id=\"stop3520\" /&gt;&lt;/linearGradient&gt;&lt;linearGradient inkscape:collect=\"always\" xlink:href=\"#linearGradient3522\" id=\"linearGradient3524\" x1=\"64.030418\" y1=\"96.847031\" x2=\"143.43111\" y2=\"96.847031\" gradientUnits=\"userSpaceOnUse\" /&gt;&lt;linearGradient inkscape:collect=\"always\" xlink:href=\"#linearGradient3584\" id=\"linearGradient3586\" x1=\"67.60627\" y1=\"98.366364\" x2=\"148.15862\" y2=\"98.366364\" gradientUnits=\"userSpaceOnUse\" /&gt;&lt;/defs&gt;&lt;g inkscape:label=\"img-top\" inkscape:groupmode=\"layer\" id=\"layer1\" style=\"display:inline\" transform=\"translate(-53.17203,-43.635959)\"&gt;&lt;text xml:space=\"preserve\" style=\"font-size:4.93889px;line-height:0.95;font-family:sans-serif;display:inline;stroke-width:0.264583\" x=\"145.31673\" y=\"68.72187\" id=\"text364\" inkscape:label=\"A'\"&gt;&lt;tspan sodipodi:role=\"line\" id=\"tspan362\" style=\"font-size:4.93889px;stroke-width:0.264583\" x=\"145.31673\" y=\"68.72187\"&gt;A'&lt;/tspan&gt;&lt;/text&gt;&lt;text xml:space=\"preserve\" style=\"font-size:4.93889px;line-height:0.95;font-family:sans-serif;display:inline;stroke-width:0.264583\" x=\"53.109329\" y=\"69.1222\" id=\"text356\" inkscape:label=\"A\"&gt;&lt;tspan sodipodi:role=\"line\" id=\"tspan354\" style=\"font-size:4.93889px;stroke-width:0.264583\" x=\"53.109329\" y=\"69.1222\"&gt;A&lt;/tspan&gt;&lt;/text&gt;&lt;path style=\"fill:none;stroke:#0000ff;stroke-width:0.265;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:none;stroke-opacity:1\" d=\"m 57.779747,66.186502 6.271707,0.13344 m 10.942123,-5.20418 c 3.257361,-3.824489 5.768834,-16.591931 11.876208,-17.347268 l 31.491965,0.13344 c 9.02277,0.304639 8.97067,10.773129 12.27653,17.480709\" id=\"path521\" sodipodi:nodetypes=\"cccccc\" inkscape:label=\"line thin\" /&gt;&lt;path style=\"fill:none;stroke:#0000ff;stroke-width:0.264583px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1\" d=\"m 140.51287,66.186502 3.20258,-0.13344\" id=\"path523\" inkscape:label=\"line thin\" /&gt;&lt;path style=\"display:inline;fill:none;stroke:#0000ff;stroke-width:1.065;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:none;stroke-opacity:1\" d=\"m 64.37479,66.27375 c 3.51625,-2.756604 7.149616,-4.459157 10.919028,-4.937299\" id=\"path1153\" sodipodi:nodetypes=\"cc\" inkscape:label=\"line thick\" /&gt;&lt;path style=\"display:inline;fill:none;stroke:#0000ff;stroke-width:1.065;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:none;stroke-opacity:1\" d=\"m 130.64854,61.051609 c 2.69577,3.040226 5.97672,4.617491 9.6847,5.127193\" id=\"path1155\" sodipodi:nodetypes=\"cc\" inkscape:label=\"line thick\" /&gt;&lt;ellipse style=\"fill:#0000ff;stroke:#0000ff;stroke-width:1.065;stroke-dasharray:none;paint-order:fill markers stroke;stop-color:#000000\" id=\"path1209\" cx=\"64.327316\" cy=\"66.178802\" rx=\"0.4272663\" ry=\"0.37979227\" inkscape:label=\"dot\" /&gt;&lt;ellipse style=\"fill:#0000ff;stroke:#0000ff;stroke-width:1.065;stroke-dasharray:none;paint-order:fill markers stroke;stop-color:#000000\" id=\"path1209-8\" cx=\"74.914024\" cy=\"61.241501\" rx=\"0.4272663\" ry=\"0.37979227\" inkscape:label=\"dot\" /&gt;&lt;ellipse style=\"fill:#0000ff;stroke:#0000ff;stroke-width:1.065;stroke-dasharray:none;paint-order:fill markers stroke;stop-color:#000000\" id=\"path1209-6\" cx=\"130.64854\" cy=\"61.241505\" rx=\"0.4272663\" ry=\"0.37979227\" inkscape:label=\"dot\" /&gt;&lt;ellipse style=\"display:inline;fill:#0000ff;stroke:#0000ff;stroke-width:1.065;stroke-dasharray:none;paint-order:fill markers stroke;stop-color:#000000\" id=\"path1209-7\" cx=\"140.61809\" cy=\"66.463654\" rx=\"0.4272663\" ry=\"0.37979227\" inkscape:label=\"dot\" /&gt;&lt;/g&gt;&lt;g inkscape:groupmode=\"layer\" id=\"layer2\" inkscape:label=\"img-bottom\" transform=\"translate(-53.17203,-43.635959)\"&gt;&lt;text xml:space=\"preserve\" style=\"font-size:4.93889px;line-height:0.95;font-family:sans-serif;display:inline;stroke-width:0.264583\" x=\"145.98393\" y=\"89.004837\" id=\"text418\" inkscape:label=\"A'\"&gt;&lt;tspan sodipodi:role=\"line\" id=\"tspan416\" style=\"font-size:4.93889px;stroke-width:0.264583\" x=\"145.98393\" y=\"89.004837\"&gt;A'&lt;/tspan&gt;&lt;/text&gt;&lt;text xml:space=\"preserve\" style=\"font-size:4.93889px;line-height:0.95;font-family:sans-serif;stroke-width:0.264583\" x=\"58.580395\" y=\"107.41962\" id=\"text360\" inkscape:label=\"A\"&gt;&lt;tspan sodipodi:role=\"line\" id=\"tspan358\" style=\"font-size:4.93889px;stroke-width:0.264583\" x=\"58.580395\" y=\"107.41962\"&gt;A&lt;/tspan&gt;&lt;/text&gt;&lt;path style=\"display:inline;fill:url(#linearGradient3586);fill-opacity:1;stroke:#000000;stroke-width:0.264583px;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:1.05833, 0.529166;stroke-dashoffset:0;stroke-opacity:1\" d=\"m 67.792919,103.20855 c 4.599387,-9.503289 12.289063,-18.282292 32.946981,-24.021863 12.12077,-1.108928 23.16637,1.62207 33.51667,6.836262 l 7.78574,4.082767 c 5.60824,7.500866 6.29687,9.877152 5.88678,11.108924 -3.26483,7.38071 -7.18384,7.23836 -10.91903,9.20996 -10.4388,5.06006 -20.66991,6.38166 -30.85812,6.93121 -8.988417,1.01278 -17.470444,0.2532 -25.446082,-2.27875 -3.993675,-1.7923 -8.342705,-2.87389 -11.393767,-6.55142 -0.969389,-1.49456 -1.797623,-3.07382 -1.519172,-5.31709 z\" id=\"path1315\" sodipodi:nodetypes=\"cccccccccc\" /&gt;&lt;path style=\"fill:#ffffff;stroke:#000000;stroke-width:0.264583px;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:1.05833, 0.529166;stroke-dashoffset:0;stroke-opacity:1\" d=\"m 77.002882,98.84094 7.026159,-6.361523 c 6.083988,-5.950949 11.770322,-8.985769 17.280549,-10.729132 7.06531,-0.658765 14.47992,0.42898 22.31279,3.608028 3.72737,1.172182 6.59804,3.415237 9.58976,5.506987 2.25277,2.747834 5.17529,4.825911 7.97564,7.026159 1.78653,2.133421 1.66729,3.949211 0,5.506991 -5.84246,3.73718 -11.81949,7.17831 -18.60982,8.83017 -4.73149,1.40464 -9.60474,2.49032 -15.09675,2.1838 -4.68506,0.4466 -8.787537,-1.24294 -12.912934,-2.84844 -3.291533,-1.31082 -6.583066,-2.39442 -9.874599,-2.5636 -2.973433,-0.1711 -5.85874,-1.04722 -8.640276,-2.75349 -0.801585,-2.11557 -1.789119,-4.17242 0.949481,-7.40595 z\" id=\"path1313\" sodipodi:nodetypes=\"ccccccccccccc\" /&gt;&lt;path style=\"fill:none;stroke:#000000;stroke-width:0.264583px;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:1.05833, 0.529166;stroke-dashoffset:0;stroke-opacity:1\" d=\"m 80.326065,98.366198 5.317093,-4.367612 9.589754,-6.36152 9.304908,-3.323183 c 6.87816,-0.02477 12.86259,1.55916 18.79972,3.228235 3.15956,1.049802 5.56485,2.853877 7.97564,4.652457 l 8.35543,6.36152 c 1.08339,1.20359 0.597,2.210955 0.18989,3.228235 -5.75066,4.27882 -11.03758,5.77526 -16.42601,7.88069 -5.95586,1.84631 -11.51884,2.25204 -16.90076,1.99391 -4.43091,-0.61103 -8.861819,-1.94866 -13.292729,-3.51308 -3.048129,-1.29307 -6.066741,-2.40904 -8.925118,-2.5636 -2.056026,-0.26064 -4.013977,-0.70108 -4.937299,-3.03834 -0.0801,-1.26037 0.477077,-2.733171 0.949481,-4.177712 z\" id=\"path1311\" sodipodi:nodetypes=\"cccccccccccccc\" /&gt;&lt;path style=\"display:inline;fill:none;stroke:#000000;stroke-width:0.264583px;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:1.05833, 0.529166;stroke-dashoffset:0;stroke-opacity:1\" d=\"m 83.459351,97.701562 6.836261,-4.082767 c 5.777343,-4.396213 9.074888,-4.659428 13.292728,-6.456468 6.61438,-0.124928 12.94692,1.15935 19.17951,2.943389 3.01596,1.078699 4.8098,2.646247 6.93121,4.082767 2.75815,1.611792 5.31325,3.325107 6.93121,5.506989 -0.34477,2.947598 -9.78734,6.397208 -15.85633,7.785738 -3.89858,0.98424 -7.87315,1.58855 -11.96346,1.61412 -5.18319,-0.71088 -10.546343,-1.06185 -15.001788,-3.22823 -1.726601,-0.57796 -3.163168,-1.54263 -5.412042,-1.42422 l -4.082767,-0.75959 c -1.426529,-0.31511 -1.879655,-1.21426 -2.373701,-2.08886 0.398131,-1.838918 0.929823,-3.010025 1.519169,-3.892868 z\" id=\"path1309\" sodipodi:nodetypes=\"ccccccccccccc\" /&gt;&lt;path style=\"display:inline;fill:url(#linearGradient3524);fill-opacity:1;stroke:#0000ff;stroke-width:0.565;stroke-linecap:butt;stroke-linejoin:miter;stroke-dasharray:2.825;stroke-dashoffset:0;stroke-opacity:1\" d=\"M 64.089946,105.39236 143.37158,88.301702\" id=\"path1301\" inkscape:label=\"line\" /&gt;&lt;/g&gt;&lt;/svg&gt;\"\"\"^^rdf:XMLLiteral ;\n.\n</code></pre> <p>This example embeds the following simple image and yet the SVG literal used is large (long):</p> <p></p> <p>Note also that the literal value used for the SVG encoding of the image is XML, indicated using the <code>rdf:XMLLiteral</code> custom datatype.</p>"},{"location":"concepts/vocabs/patterns/#blank-node","title":"Blank Node","text":"<p>Here an image at a local file path is given a caption and a copyright notice via a Blank Node of type <code>schema:ImageObject</code> using other schema.org predicates:</p> <pre><code>PREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n\n:dog\n  a skos:Concept ;\n  skos:prefLabel \"Dog\"@en ;\n  skos:altLabel \"Domestic Dog\"@en ;\n  skos:definition \"The dog (Canis familiaris or Canis lupus familiaris) is a domesticated descendant of the gray wolf.\"@en ;\n  skos:example [\n    a schema:ImageObject ;\n    schema:contentLocation \"src/img/my_dog.jpg\" ;\n    schema:caption \"Fido, Nicholas' dog\" ;\n    schema:copyrightNotice \"&amp;copy; Nicholas Car, 2025\" ;  \n  ] ;\n.\n</code></pre>"},{"location":"concepts/vocabs/patterns/#discussion","title":"Discussion","text":"<p>There are several ways to associate images with Concepts in SKOS vocabularies and each have different pros and cons. Be sure to determine how your target vocabulary creation / management / publication systems handle images too.</p>"},{"location":"concepts/vocabs/patterns/#related","title":"Related","text":""},{"location":"concepts/vocabs/patterns/#systems","title":"Systems","text":"<p>The following is a list of KurrawongAI-supported vocabulary systems that have some image capability:</p> <ul> <li>VocExcel<ul> <li>for the creation of vocabs</li> <li>VocExcel v0.8.0, due for release in Jun, 2025, will contain an <code>skos:example</code> slot for Concepts that can be used to link to an image via URL</li> </ul> </li> <li>VocEdit<ul> <li>for the creation of vocabs</li> <li>VocEdit already (May 2025) supports adding any predicated and literal values to Concepts, so the URL and local file path methods can be used now</li> <li>the July 2025 release of VocEdit will support uploading small SVG files for the values of <code>skos:example</code> or <code>schema:image</code> predicates </li> </ul> </li> <li>Prez<ul> <li>for the display of images in vocabs</li> <li>already supports rendering of embedded SVG images<ul> <li>see an example: the KurrawongAI Image Test vocab Concept of 'Plane'</li> </ul> </li> <li>will soon support loading of remote images linked to via URL</li> </ul> </li> </ul>"},{"location":"concepts/vocabs/vocab-reuse/","title":"Vocabulary Reuse","text":"<p>Scope</p> <p>This content is in intended to provide guidance on the effective reuse of vocabularies. It will explain the benefits of reuse; how to locate suitable existing vocabularies; how do to make attribution and manage provenance in reused vocabularies and vocabulary segments. </p> <p>Audience</p> <p>This module is primarily targeted to managers and users (vocab owners and contributors) of established vocabularies. It is assumed that learners have some experience with using document management or version control systems, and general familiarity with data management in practice.</p> <p>Outcome</p> <p>Learners should be able to adopt vocabularies in part or in whole into their local contexts. Learners will understand implications for managing externally sourced vocabularies as part of local operations</p> <p>\ud83d\udca1 Identifies troubleshooting tips, common errors and potential issues.</p> <p>\ud83d\udcdd Notes that summarise content at the end of a module.</p>"},{"location":"concepts/vocabs/vocab-reuse/#an-introduction-to-vocabulary-reuse","title":"An Introduction to vocabulary reuse","text":"<p>Whatever domain we work in, there's a fair chance that useful vocabularies have already been developed by third parties. And as for any data management operation, it's a good idea to seek opportunities to reuse existing vocabularies. In this module we'll cover: - Weighing up the effort: reuse vs build from scratch. - Finding existing vocabularies that meet your scenario - Evaluating the suitability, and reuse-ability of existing vocabularies - Matching vs importing external concepts - Adopting parts vs whole vocabularies - Attribution and provenance: representing and preserving primary sources.</p>"},{"location":"concepts/vocabs/vocab-reuse/#weighing-it-up","title":"Weighing it up","text":"<p>Is it worth reusing existing vocabularies in part or whole? There are a various patterns that can be followed:</p> <ul> <li>Referencing vocabularies: match home-grown concepts with concepts in external vocabularies . </li> <li>Importing concepts: some or perhaps most of your vocabulary comprises concepts sources from existing vocabularies, faithfully retaining and presenting definitions and other metadata from the source;</li> <li>Verbatim: access and reuse a vocabulary as is, with only exceptional customisation.</li> </ul> <p>Decision workflow</p>"},{"location":"concepts/vocabs/vocab-reuse/#build-from-scratch","title":"Build from scratch","text":"<p>Why not develop a vocabulary from scratch, with sources of warrant that you know are relevant to your community and use case?</p> <p>Even if you build from scratch, you might consider developing a vocabulary that is itself reuse-able in your industry, sector or in other regions. The more use your vocabulary gets, the more interopoerabilty you have with other systems and catalogues. If you want your vocabulary reused, ensure: - clear rights and licensing are declared, within the vocabulary concept scheme and in surrounding web context - governance arrangements for the vocabulary are stated somewhere - build trust by declaring the update history and cycle, and committments to persisting concept IRI - distributions: ensure your vocabulary can be accessed in standard formats and over stand APIs (see Vocabulary Systems for more about this)</p>"},{"location":"concepts/vocabs/vocab-reuse/#finding-vocabularies","title":"Finding vocabularies","text":"<p>There may already be vocabularies that match the theme and scope of your metadata catalogues. They may exist in a nearby knowledge domain, industry or sector, and may originate in other global regions. be vocabularies available for reuse listed in vocabulary registries, such as:</p> <ul> <li>Research Vocabularies Australia: vocabularies span a wide range of research and industry domains. Vocabulary search can be filtered by format and licensing, and many may be accessed directly from the RVA site via download or API.</li> <li>BARTOC.org: this is an international registry of vocabularies and ontologies in many languages and with over 2,500 records. </li> <li>Linked Open Vocabularies: a community-curated catalog of RDF vocabularies used in Linked Data communities. LOV provides metadata, usage statistics, and interlinking information for vocabularies.</li> <li>ID.LOC.GOV - Linked Data Service: the Library of Congress vocabularies widely used, especially for describing bibliographic data.</li> </ul> <p>If you are searching the web for useful vocabularies, consider broadening your keyword search to include taxonomny; classification; thesaurus; ontology.  <pre><code>flowchart TD\n    Source([Source])\n    Query([Query])\n    Glossary[[Glossary]]\n    Taxonomy[[Taxonomy]]\n    Thesaurus[[Thesaurus]]\n    SubjectHeadings[[Subject Headings]]\n\n    Source --&gt;|Any combination of vocabulary type AND industry, discipline or sector| Query\n    Query --&gt;|Find all vocabularies used in social services.| Glossary\n    Query --&gt;|Find all taxonomies from 2006 to present that mention minerals or mining| Taxonomy\n    Query --&gt;|Find all thesauruses or thesauri in philosophy that include English and French labels| Thesaurus\n    Query --&gt;|Find all medical vocabularies used in the Asia-Pacific region.| SubjectHeadings</code></pre></p>"},{"location":"concepts/vocabs/vocab-reuse/#language","title":"Language","text":"<p>It is perhaps unnecessary to mention that a vocabulary fit for reuse needs to be comprehensible in the language of expected users. A skos:conceptScheme will typically list the language codes used for skos:concept labels, and in many cases there will be more than one - multilingual vocabularies are fairly common. If an existing vocabulary includes language labels that are not needed in a local context, they can be ignored (a local system is configured to only process labels with a given language tag). However, if parts of a vocabularyu are to be adopted (see Adoption), it might be worth considering whether managing a partially-multilingual vocabulary is an unwanted or unnecessary complication in your context.  </p> <p>Even within a natural language, there may be regional differences. </p> <pre><code>@prefix policy: &lt;https://linked.data.gov.au/def/policy/&gt; .\n@prefix skos: &lt;http://www.w3.org/2004/02/skos/core#&gt; .\n@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .\n@prefix rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .\n@prefix dcterms: &lt;http://purl.org/dc/terms/&gt; .\n\nfast:\n\npolicy:7353843a-9107-49af-bcd0-a8eac00bcd54 a skos:Concept ;\n    skos:prefLabel \"Socioeconomic status\"@en ;\n    skos:exactMatch &lt;http://id.worldcat.org/fast/1123359&gt; ;\n</code></pre>"},{"location":"concepts/vocabs/vocab-reuse/#double-check-can-i-reuse-this","title":"Double check: can I reuse this?","text":"<p>Check an existing vocabulary for rights and licensing statements. Information about terms and conditions should be stated within the <code>skos:conceptScheme</code>, but might be stated outside the vocabulary data in a non-semantic resource (such as a vocabulary landing page). Some properties to check for include: - <code>sdo:license</code> / <code>dcterms:license</code> - <code>dcterms:accessRights</code> - <code>sdo:copyrightHolder</code> / <code>isorole:rightsHolder</code></p> <p>Tip: Even if a vocabulary may be reused, some attribution may be needed in your local context. If derivations to the vocabulary are planned, they may need to be shared as a condition of reuse.</p>"},{"location":"concepts/vocabs/vocab-reuse/#mapping-concepts-with-other-vocabularies","title":"Mapping concepts with other vocabularies","text":"<p>In the basic structure of a vocabulary, concepts may be related to other concepts via broader, narrower or related properties. Sometimes a concept needs to be related to a concept in a different vocabulary. Concept matching across vocabularies is done in a similar way but with different properties: Broad match, Narrower match, Related match.</p> <p>Broad match example:</p> <p>Limestone packstone <code>skos:broadMatch</code> Packstone ... where Limestone packstone is a concept in the GSWA rock classification scheme, and Packstone is a concept in the INSPIRE code list register.</p> <p>Exact match example:</p> <p>Child support <code>skos:exactMatch</code> Child support ... where Child support is a concept in both Public Policy Taxonomy and FAST.</p>"},{"location":"concepts/vocabs/vocab-reuse/#notes","title":"Notes","text":"<p>Note fields are available for each concept. A definition, such as found in a glossary, is required by VocPub (AGLDWG, n.d.). A definition is not intended to be an exhaustive treatment of a concept, but rather explains the scope and usage of the concept.</p> <p>A <code>skos:historyNote</code> is a useful property for vocabulary managers to track decisions that have been made about a concept (label changes, new broader relationships). It can also be used to make a statement about the origin of a concept.</p> <p>\ud83d\udca1 Tip: When writing notes, use plain text only and limit paragraph breaks where possible.</p>"},{"location":"concepts/vocabs/vocab-reuse/#concept-scheme","title":"Concept scheme","text":"<p>A Concept scheme is some metadata about the vocabulary as a whole - the vocabulary title (<code>skos:prefLabel</code>), a definition (<code>skos:definition</code>), and a unique identifier are minimum requirements. All vocabularies must have a Concept scheme, and the Concept scheme should include:</p> <ul> <li> <p>an Identifier - create an IRI following the same pattern as the IRIs for concepts. For the suffix, instead of a concept ID, add a Concept scheme ID. This may be the name of the Concept scheme (the vocabulary), e.g.: - <code>https://linked.data.gov.au/def/road-types</code>   ... where Road types is the name of the concept scheme.</p> </li> <li> <p>a Preferred label - the same property that is used for a Concept. Use a Preferred label for the name or title of the vocabulary (this may also be used for the Concept scheme ID)</p> </li> <li>a Definition - a definition of the Concept scheme. Use plain text only but paragraphs may be separated by newlines. Also used for Concepts</li> <li>a Created date. When the Concept scheme was first created. This might be automatically created by a vocabulary editor</li> <li>a History note - a note on the origin or history of a vocabulary - such as how or from what it was generated.</li> </ul>"},{"location":"concepts/vocabs/vocab-reuse/#exercise-add-imported-concepts-to-a-collection","title":"Exercise: add imported concepts to a collection","text":"<p>When a vocabulary imports 6 A <code>skos:collection</code> references a <code>skos:concept</code> using the <code>skos:member</code> property.</p>"},{"location":"concepts/vocabs/vocab-reuse/#optional-elements","title":"Optional elements","text":"<p>You can add more metadata to your Concepts and Concept schemes that will improve the clarity, scope and provenance of your vocabulary. Consider the following additional elements:</p>"},{"location":"concepts/vocabs/vocab-reuse/#citation","title":"Citation","text":"<p>Use the Citation element to provide an optional hyperlink to or textual description of source information.</p>"},{"location":"concepts/vocabs/vocab-reuse/#derived-from","title":"Derived from","text":"<p>Use derived from to reference an IRI for an external vocabulary from which the vocabulary is derived.</p>"},{"location":"concepts/vocabs/vocab-reuse/#derivation-mode","title":"Derivation mode","text":"<p>A Derivation mode value is mandatory if a value is given for the <code>prov#wasDerivedFrom</code> property. Derivation mode concepts are selected from the Vocabulary Derivation Modes vocabulary.</p>"},{"location":"concepts/vocabs/vocab-reuse/#notation","title":"Notation","text":"<p>All concepts must have an IRI, and the IRI identifier may be a completely opaque string based on nothing other than a randomly generated string (such as from the UUID scheme). However, concepts may optionally store a <code>skos:notation</code>, which is like a secondary identifier and is based on some source or reference data that the concept was derived from.</p>"},{"location":"concepts/vocabs/vocab-reuse/#defining-vocabulary-iri","title":"Defining vocabulary IRI","text":"<p>A concept may be 'imported' from another vocabulary. We can assume that a concept is imported if it shares the same or very similar metadata (such as a <code>skos:definition</code>) and labels. Such concepts should indicate the defining vocabulary from where they were imported. Read more about importing concepts and references. </p>"},{"location":"concepts/vocabs/vocab-reuse/#citation_1","title":"Citation","text":"<p>For each concept, a Citation, an optional reference to or textual description of some source information, may be given.</p> <p>Example:</p> <pre><code>IRI: https://data.idnau.org/pid/vocab/policy-types/policy\nprefLabel: policy\ndefinition: A strategic directive and high-level description of desired behaviour developed by an organisation to help govern how it functions...\ncitation: https://policy.usq.edu.au/documents/14266PL\n</code></pre> <p>... where the Citation refers to a policy definition originating from an external source. In this example the URL of the source is given so that it can be easily looked up and, if needed, verified and validated.</p>"},{"location":"concepts/vocabs/vocab-reuse/#reuse-existing-vocabularies","title":"Reuse existing vocabularies","text":"<p>It's worth checking if there are existing vocabularies (published by a third party) that match your requirements. In this section we will discuss: - finding and identifying vocabularies for reuse - workflows to suit vocabulary formats - derivation modes: the type and extent of reuse - how to indicate provenance and attribution</p>"},{"location":"concepts/vocabs/vocab-reuse/#reuse-non-semantic-vocabularies","title":"Reuse non-semantic vocabularies","text":"<p>Building a vocabulary from scratch, with the editing and validation tools mentioned here, ensures vocabularies are well-formed and presented. Existing vocabularies published in other contexts may not be so well-formed! Existing vocabularies, including those found via vocabulary registries, will vary in their conformance with data standards such as RDF and SKOS, before even considering quality standards like VocPub and qSKOS (W3C, n.d.). Here are a couple of challenges to consider:</p> <ul> <li>Unstructured: an existing vocabulary is well presented by not machine-readable, such as in PDF or HTML. The vocabulary terms may indicate properties and relationships, but these properties themselves are not machine-readable. The vocabulary may need to be scraped and cleaned, eventually transformed into an RDF format compatible with a SKOS editing tool.</li> <li>Unidentified: a vocabulary with labels but no identifiers - new IRIs will need to be constructed in this case. </li> </ul> <p>Tip: When constructing IRIs for an existing vocabulary, base the IRI suffix on any existing identifiers or tokens that may be present in the vocabulary. </p>"},{"location":"concepts/vocabs/vocab-reuse/#derivation-modes","title":"Derivation modes","text":"<p>Consider the extent and type of derivation, there will be different requirements and implications for using existing vocabularies</p>"},{"location":"concepts/vocabs/vocab-reuse/#verbatim","title":"Verbatim","text":"<p>While using an existing vocabulary as-is requires no editing work, there will usually be a need to attribute the creator or publisher within your local business context.</p>"},{"location":"concepts/vocabs/vocab-reuse/#customisations","title":"Customisations","text":"<p>Minor changes may be made to vocabularies to meet local requirements. Vocabulary concepts may be added; labels may be updated (changes to spelling or swapping an <code>skos:altLabel</code> for <code>skos:prefLabel</code>). Changes will need to be acknowledged at both the concept and concept scheme level.</p>"},{"location":"concepts/vocabs/vocab-reuse/#adoption","title":"Adoption","text":"<p>Importing a cluster of concepts from an existing vocabulary into a local vocabulary project. The provenance of adopted concepts must be stated.</p> <p>Example:</p> <p>We will import a concept from the LOD SRTI DATEX II ontology into the Road Travel Direction vocabulary.</p> <p>LOD SRTI DATEX II models 'Named individuals', which are enumerated instances of various properties. For example, the property <code>srti:DirectionEnum</code> has member the named individual <code>srti:clockwise</code>. We will import model this named individual as a skos:concept and import it into the Road travel direction vocabulary.</p> <p>To import the concept we will need to update the prefix declarations and <code>skos:conceptScheme</code> and add a new <code>skos:concept</code> and <code>skos:collection</code></p> <ul> <li> <p>Open the VocPub Turtle file used in the editing steps in a text editor.</p> </li> <li> <p>Add <code>srti</code> to the prefixes:</p> </li> </ul> <pre><code>PREFIX : &lt;https://linked.data.gov.au/def/road-travel-direction/&gt;\nPREFIX agldwgstatus: &lt;https://linked.data.gov.au/def/reg-statuses/&gt;\nPREFIX cs: &lt;https://linked.data.gov.au/def/road-travel-direction&gt;\nPREFIX dcterms: &lt;http://purl.org/dc/terms/&gt;\nPREFIX droles: &lt;https://linked.data.gov.au/def/data-roles/&gt;\nPREFIX owl: &lt;http://www.w3.org/2002/07/owl#&gt;\nPREFIX prov: &lt;http://www.w3.org/ns/prov#&gt;\nPREFIX reg: &lt;http://purl.org/linked-data/registry#&gt;\nPREFIX sdo: &lt;https://schema.org/&gt;\nPREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\n# Added new prefix \"srti\":\nPREFIX srti: &lt;https://cef.uv.es/lodroadtran18/def/transporte/dtx_srti/&gt;\nPREFIX themes: &lt;https://linked.data.gov.au/def/fsdf/themes/&gt;\nPREFIX xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt;\n</code></pre> <ul> <li>Add the following <code>skos:concept</code> and properties:</li> </ul> <p><pre><code>srti:clockwise\n    a skos:Concept ;\n    dcterms:created \"XXXX-XX-XX\"^^xsd:dateTime ;\n    dcterms:creator &lt;http://editor.example.com/foo&gt; ;\n    dcterms:modified \"XXXX-XX-XX\"^^xsd:dateTime ;\n    dcterms:definition \"A rotational direction that moves in the same pattern as the hands of a clock\" ;\n    skos:topConcept cs: ;\n    skos:prefLabel \"Clockwise\"@en ;\n</code></pre> - Add the concept to the <code>skos:conceptScheme</code></p> <pre><code>  cs:\n    a skos:ConceptScheme ;\n    sdo:keywords themes:transport ;\n    dcterms:created \"2023-05-30\"^^xsd:date ;\n    dcterms:creator &lt;https://linked.data.gov.au/org/qsi&gt; ;\n    dcterms:identifier \"road-travel-direction\"^^xsd:token ;\n# Date modified will be incremented:\n    dcterms:modified \"XXXX-XX-XX\"^^xsd:date ;\n    dcterms:publisher &lt;https://linked.data.gov.au/org/icsm&gt; ;\n    reg:status agldwgstatus:experimental ;\n    owl:versionIRI :1.0 ;\n    owl:versionInfo \"1.0\" ;\n    skos:definition \"This vocabulary describes the travel direction assigned to a section of a road. \"@en ;\n    skos:hasTopConcept\n        :bi-directional ,\n# Added new concept \"clockwise\":\n        :clockwise ,\n        :none ,\n        :one-way ,\n        :one-way-against-vector ,\n        :one-way-with-vector ,\n        :unknown ;\n# History note extended\n    skos:historyNote \"This vocabulary was created by the Queensland Spatial Information services and imports some concepts from other vocabularies\" ;\n    skos:prefLabel \"Road Travel Direction\"@en ;\n    prov:qualifiedAttribution\n        [\n            prov:hadRole droles:custodian ;\n            prov:agent &lt;https://linked.data.gov.au/org/icsm&gt;\n        ] ;\n</code></pre> <ul> <li>Create new <code>skos:collection</code></li> </ul> <pre><code>:srti-vocabulary\n    a skos:Collection ;\n    dcterms:source \"https://cef.uv.es/lodroadtran18/def/transporte/dtx_srti/\"^^xsd:anyURI ;\n    rdfs:isDefinedBy cs: ;\n    skos:definition \"Concepts from the LOD SRTI DATEX II ontology\" ;\n    skos:inScheme cs: ;\n    skos:member\n        &lt;http://cef.uv.es/lodroadtran18/def/transporte/dtx_srti#clockwise&gt; ;\n    skos:prefLabel \"LOD SRTI DATEX II\"@en ;\n    prov:wasDerivedFrom &lt;https://cef.uv.es/lodroadtran18/def/transporte/dtx_srti/&gt; ;\n.\n</code></pre> <ul> <li>Select \"One Way From To\"</li> <li>Open Concept relationships</li> <li>Open options for Broader</li> <li>Select Add an IRI value</li> <li>From the new dropdown box, select (or search for) \"One way\"</li> <li>Select the Tick button</li> <li>Go to Project &gt; Save</li> <li>Navigate to the <code>road-travel-directions.ttl</code> file, open it, and note that there is a new <code>skos:broader</code> relationship.</li> </ul>"},{"location":"concepts/vocabs/vocab-reuse/#references-and-further-reading","title":"References and Further Reading","text":"<ul> <li>AGLDWG. (n.d.). VocPub profile specification. Retrieved April 17, 2025, from https://agldwg.github.io/vocpub-profile/specification.html</li> <li>W3C (n.d.). QSKOS. Retrieved March 5, 2025, from https://www.w3.org/2001/sw/wiki/QSKOS</li> <li>W3C (2009). SKOS reference. https://www.w3.org/TR/skos-reference/</li> <li>W3C (2014). Turtle: Terse RDF triple language (W3C Recommendation). Retrieved from https://www.w3.org/TR/turtle/</li> </ul>"},{"location":"products/olis/","title":"Olis Overview","text":"<p>Olis is a graph management application. Its job is to help administrators of Knowledge Graphs manage them as a series of sub-graphs. Olis uses the Olis Ontology as its data model.</p> <p>Data in a Knowledge Graph can be segmented into sub-graphs in a manner similar to the way in which schemas in some relational database systems can segment data. Multiple graphs can then be used together to form the total Knowledge Graph but managed separately, if required.</p> <p>Olis provides a model and an API for managing Knowledge Graph sub-graphs. The Olis data model defines:</p> <ul> <li>Real Graphs<ul> <li>Knowledge Graph sub-graphs that contain data</li> </ul> </li> <li>Virtual Graphs<ul> <li>Knowledge Graph sub-graphs that are aliases for other Real and Virtual graphs and contain none of their own data</li> </ul> </li> </ul> <p>Using the Olis API, you can make Virtual Graphs for complex datasets that consist of potentially very many Real Graphs and other Virtual Graphs that segment the dataset's data by time or some other dimension. Olis provides a place to view the statistics on record sizes in Graphs, which may also represent different data loads.</p>"},{"location":"products/olis/#communication","title":"Communication","text":"<p>Olis UI: - Makes requests to the Olis APIs via HTTPS and returns HTTPS responses. - These requests return server rendered pages or data payloads.</p> <p>Olis API service: - Olis APIs make requests to a triple store via HTTP(S) and returns HTTP(S) responses. - Olis APIs may query via the read-only SPARQL endpoint or send admin requests the the Fuseki admin API endpoint - Olis APIs communicates with Redis over TCP/IP (see https://redis.io/docs/latest/develop/reference/protocol-spec/#network-layer)</p> <p>SSL encryption and PORT number for requests to the triple store are determined by the <code>SPARQL_ENDPOINT</code> environment variable which specifies a URL endpoint for the triple store. Similar to how the Prez API service is configured. However, for Olis there are two SPARQL endpoints defined in the configuration, one is the readonly internal endpoint, the other is the internal update endpoint. In addition the Redis internal connection configuration is specified in a similar way.</p> <pre><code>  OLIS__SPARQL_ENDPOINT=https://fuseki/olis\n  OLIS__SPARQL_UPDATE_ENDPOINT=https://fuseki/olis\n  OLIS__SPARQL_USERNAME=username\n  OLIS__SPARQL_PASSWORD=password\n  OLIS__REDIS_HOST=my.redis.cache.windows.net\n  OLIS__REDIS_PORT=6380\n  OLIS__REDIS_PASSWORD=myRedisAccessKey\n  OLIS__REDIS_SSL=1\n</code></pre> <p>SSL encryption and PORT number for communication with the client are dependent on how Prez is deployed. For example, if deploying with Azure App Service, All communication from the client to Prez will be via HTTPS using the default HTTPS port of 443.</p>"},{"location":"products/olis/#authentication","title":"Authentication","text":"<p>Olis has built in user administration management, however, integration with other middle-ware to authenticate and authorise client requests is possible.</p>"},{"location":"products/olis/#authentication-to-the-triple-store","title":"Authentication to the triple store","text":"<p>Olis supports basic authentication with [[Knowledge Base/Products/Supported 3rd Party/Fuseki|Fuseki]] by setting the <code>SPARQL_USERNAME</code> and <code>SPARQL_PASSWORD</code> environment variables.</p> <p>If Fuseki is also deployed to Azure App Service then a combination of EasyAuth and System Identities can be used to provide Azure AD integrated authentication. (Further work to outline accepted auth solution).</p>"},{"location":"products/olis/#configuration","title":"Configuration","text":"<p>When deploying Olis to Azure App Service, environment variables can be set by creating Application Settings.</p>"},{"location":"products/olis/#components","title":"Components","text":"<p>Olis UI - The Olis user interface provides a platform for administrators to manage the virtual to real graph mappings or to run a SPARQL query through a SPARQL UI interface. The Olis UI communicates with the Olis admin APIs to perform the graph admin functions.</p> <p>Olis Services (or admin APIs for the Olis UI) - Olis APIs provide functionality to deliver the Olis web assets along with the functional admin API calls required to administer the graphs.</p> <p>Redis cache - Olis uses Redis to cache application data. Azure cache for Redis is a compatible service that can be used for this purpose.</p>"},{"location":"products/olis/#request-flow","title":"Request flow","text":""},{"location":"products/3rdparty/fuseki/","title":"Fuseki","text":"<p>Fuseki is an Apache Software Foundation free and open source product that is part of the Jena RDF framework. It is a database system that implements the SPARQL Protocol which means you can run Fuseki to expose RDF data.</p> <p>KurrawongAI has extensive experience in deploying Fuseki for clients and can also provide a range of Fuseki support services. To find out more, visit our website.</p> <p>This guide outlines the various Fuseki data loading methods available and provides detailed procedures for each.</p>"},{"location":"products/3rdparty/fuseki/#contents","title":"Contents","text":"<ul> <li>Data Loading Methods</li> <li>Data Loading Procedures<ul> <li>SPARQL</li> <li>Kurra CLI - Graph Store Protocol</li> <li>tdbloader</li> <li>RDF Delta</li> </ul> </li> </ul>"},{"location":"products/3rdparty/fuseki/#data-loading-methods","title":"Data Loading Methods","text":"<p>There are a number of tools/methods that can be used for loading data to Fuseki databases. Both the size of the database and the dataset being loaded will dictate which method is most suitable, as indicated in the Traffic Light Matrix and related notes below.</p> <p>Refer to the Data Loading Procedures section for the detailed steps required for each loading tool/method.</p> <p>Traffic Light Matrix for data loading methods </p> Matrix Notes: 1. Can be verbose, useful for scripts inserting/creating small amounts of data. 2. Good option. 3. Running tdbloader and related set up can be more effort than it is worth for small datasets. 4. Setting up RDF Delta can be more effort than it is worth for small datasets. 5. Not recommended. 6. Has appeared to worked in the hundreds of MB but seems to cause issues with Fuseki. 7. Good option. 8. Good option. 9. Good option. May not have record of addition if query is not saved. 10. Good option. 11. Requires dataset to be offline, or performed on replica. Not worth the effort for small additions.12. Good option. 13. Not recommended.14. Somewhere between 50 MB to 1 GB this is a bad idea. 15. Requires dataset to be offline, or performed on replica. Must run in append mode; slower than sequential loader. Cannot use xloader, so restricted in size. 16. Good option. 17. Good option. May not have record of update if query is not saved. 18. Can only update at the graph level (PUT). 19. Requires dataset to be offline, or performed on replica. Not worth the effort for small additions. Requires update to be written in SPARQL. 20. Good option. 21. Not recommended. 22. Not recommended. 23. Requires dataset to be offline, or performed on replica. Requires update to be written in SPARQL. 24. Good option."},{"location":"products/3rdparty/fuseki/#data-loading-procedures","title":"Data Loading Procedures","text":""},{"location":"products/3rdparty/fuseki/#sparql","title":"SPARQL","text":""},{"location":"products/3rdparty/fuseki/#scenarios","title":"Scenarios","text":"<p>SPARQL is recommended as a method for small additions/deletions/updates to new or existing datasets. It is not recommended for large operations for both performance reasons (on large instances this may not be an issue), and also because the provenance of changes made to the database through SPARQL updates are not captured (unless specifically set up through an external process). </p> <p>One caveat is that SPARQL can be used with the tdbupdate command line utility to directly update large Fuseki TDB2 datasets, though the TDB2 dataset must be offline to do this.</p> <p></p>"},{"location":"products/3rdparty/fuseki/#steps-to-accomplish","title":"Steps to accomplish","text":"<p>The SPARQL Update specification sets out a number of methods for updating RDF Data in Triplestores via update queries. These updates, deletes, or additions are done using the general patterns specified below, where \u201c{ }\u201d has been used to denote graph or triple patterns e.g. { GRAPH ?g { ?s ?p ?o } } or { ?s ?p ?o } (or equivalent expressions with IRIs or RDF Literals).</p> <p>Insertion of new data \u201cinline\u201d i.e. directly specifying the data to insert: <pre><code>INSERT DATA { }\n</code></pre></p> <p>Insertion of new data based on existing data in the dataset: <pre><code>INSERT { }\nWHERE { }\n</code></pre></p> <p>Deletion of data \u201cinline\u201d i.e. directly specifying the data to delete: <pre><code>DELETE DATA { }\n</code></pre></p> <p>Deletion of data based on existing data in the graph: <pre><code>DELETE { }  \nWHERE  { }\n</code></pre></p> <p>Update of data based on existing data in the graph: <pre><code>DELETE  { }\nINSERT  { }\nWHERE  { }\n</code></pre></p>"},{"location":"products/3rdparty/fuseki/#kurra-cli-graph-store-protocol","title":"Kurra CLI - Graph Store Protocol","text":""},{"location":"products/3rdparty/fuseki/#scenarios_1","title":"Scenarios","text":"<p>The Graph Store Protocol can be used in a range of scenarios, it is generally less preferred for larger datasets. While local uploads of large files have been done successfully this is not always reliable in cloud environments.</p> <p></p>"},{"location":"products/3rdparty/fuseki/#steps-to-accomplish_1","title":"Steps to accomplish","text":"<p>You have a new Fuseki instance without any data in it, and you want to load in a small amount of data. You have already created a new Fuseki dataset named \u201cds\u201d along with the following Fuseki endpoint permission in the Fuseki configuration file.</p> <pre><code>:service_tdb_all  \n    a  fuseki:Service ;  \n    fuseki:endpoint  [ fuseki:operation  fuseki:gsp-rw ] .\n</code></pre> <p>The above sets the Fuseki service with gsp-rw, which allows read and write operations on the unnamed Graph Store Protocol endpoint. Assuming the Fuseki instance is available at localhost:3030, the above \u201cds\u201d dataset will be available at http://localhost:3030/ds with both read and write capabilities available.</p> <p>Using uv or a similar python executable manager, install the kurra CLI utility from https://github.com/Kurrawong/kurrawong-python.</p> <p>uv tool install https://github.com/Kurrawong/kurrawong-python/archive/refs/tags/0.4.1.zip</p> <p>The kurra command is now available. Use the fuseki upload subcommand to upload RDF data files to the \u201cds\u201d dataset via the HTTP Graph Store Protocol.</p> <p><code>kurra fuseki upload background-resources/ http://localhost:3030/ds -u admin -p fuseki</code></p> <p>The tool can upload RDF data from both directories or individual files on the filesystem. In the above example, we are uploading all files from the background-resources directory.  </p> <p>If Fuseki has been configured with a custom shiro.ini and it is protected by basic authentication, you can add the -u and -p flags to specify the username and password, respectively.</p>"},{"location":"products/3rdparty/fuseki/#tdbloader","title":"tdbloader","text":""},{"location":"products/3rdparty/fuseki/#scenarios_2","title":"Scenarios","text":"<p>The following scenarios are appropriate for use with the tdbloader command line utilities.</p> <p></p> <p>Simple Deployments For simple deployments where RDF Delta is not required, the preferred data loading method is to use the Jena tdb2.tdbloader command line utility to generate the database files.</p> <p>Advantages - Fast for a large amount of data. - It uses the same module that Jena uses internally to create database files but is decoupled from the HTTP server, and is thus faster because it does not need to allow for handling of requests while the generation is in progress.</p> <p>Disadvantages - Requires the orchestration of another component (the tdb2-generation image), and  - is not preferable for making additions or updates to the data after the initial generation. And thus may only ever be used once.</p>"},{"location":"products/3rdparty/fuseki/#steps-to-accomplish_2","title":"Steps to accomplish","text":"<ol> <li>Install the Jena command line tools</li> <li>Run the tdb2.tdbloader command (it takes RDF files as input and produces a TDB 2 database as output.)</li> <li>Upload the database files to the location required for the deployed Fuseki instance. (for example, if Fuseki is deployed to a cloud VM, then the files must be copied to the cloud VM disk under <code>/fuseki/databases</code> or similar)</li> </ol> <p>Note: There exists the tdb2-generation image, which is a wrapper around these operations and more. It can also create the spatial and text indexes that may be required for the database.</p>"},{"location":"products/3rdparty/fuseki/#rdf-delta","title":"RDF Delta","text":"<p>RDF Delta is a system for recording and publishing a set of changes made to RDF Datasets in Fuseki. Its main goal is to provide a deployment stack that allows for a highly available Fuseki cluster that scales horizontally. </p> <p>The deployment stack follows a hybrid model between eventual consistency and a master-slave architecture where the RDF Delta Servers acts as the master, can receive writes in the form of RDF patch logs, and propagates them to the Fuseki instances, which are the slaves. A caveat to this master-slave architecture is that RDF Delta Servers can only receive RDF patch logs and not SPARQL Update queries. For this case, the SPARQL Update queries must be executed on the Fuseki dataset\u2019s SPARQL endpoint whereby the query immediately updates the Fuseki database, generates a set of patch logs, and sends them to the RDF Delta Servers for further propagation.</p>"},{"location":"products/3rdparty/fuseki/#scenarios_3","title":"Scenarios","text":"<p>RDF Delta is an appropriate solution for loading or updating all sizes of datasets, however, it requires more effort to set up than other methods. Once set up, a smaller amount of effort is required to write additional \u201cproducers\u201d to update Fuseki.</p> <p></p> <p>Complex deployments In many scenarios, it may be necessary to incorporate the RDF Delta system into the Fuseki deployment. In this case, the tdb2.tdbloader utility is not recommended for loading new datasets, as the patch log database is the source of truth rather than the tdb2 database.</p> <p>Advantages - This can be performed against the live server, and - is the same way that data loading can be performed for additions and updates.</p> <p>Disadvantages - Not as fast as TDB2 loader for large volumes of data.</p>"},{"location":"products/3rdparty/fuseki/#submitting-rdf-patch-logs-to-the-rdf-delta-server","title":"Submitting RDF patch logs to the RDF Delta Server","text":"<p>RDF Delta comes with a suite of command line tools that aid in performing actions against the RDF Delta Server, including adding new RDF patch logs.  </p> <p>Append a new patch log to a dataset. <code>dcmd get --server URL --dsrc NAME PATCH ...</code></p> <p>If you have an RDF file and not a patch log, you can use the r2p tool to convert an RDF file to a patch log. <code>dcmd rdf2patch FILE</code></p> <p>The command line tools are just wrappers around an undocumented HTTP API. To aid in programmatically interfacing with the RDF Delta Server, use the python rdf-delta library.</p>"},{"location":"products/3rdparty/fuseki/#submitting-sparql-update-queries-to-fuseki","title":"Submitting SPARQL Update queries to Fuseki","text":"<p>SPARQL Update queries are submitted exactly the same way as documented in the SPARQL Data Loading Procedure. The RDF Delta module in the Fuseki instance will handle the processing of the SPARQL query, generating patch logs, and submitting it to the RDF Delta Server in the background.</p>"},{"location":"products/3rdparty/fuseki/#rdf-delta-and-event-sourcing","title":"RDF Delta and Event Sourcing","text":"<p>This section speaks to an event-driven architecture where the event sourcing pattern is the primary method of updating the system\u2019s state. </p> <p>In an event sourcing system, it is critical for all update actions that mutate the system\u2019s state are processed through the event stream and persisted in the event broker. The event stream becomes a firehose of real-time information that can be used for auditing and analytical purposes, or be replayed as part of the data restore process. The event stream also serves as a way for other systems to hook into and be notified when certain interesting changes are made to the system. Additionally, the event stream also provides a straightforward way to add additional middleware layers when business requirements change without having to rewrite or re-architect the system as a whole.  </p> <p>There may be multiple event streams in the data flow, but there\u2019s usually just one main topic that all producers use as the API to submit changes to the system. This API must establish a message specification where all producers and consumers must conform to. A message generally has a set of standard headers described using the vocabulary and structure in ladb-schemas - Patch Log Header Example with a message body containing actual content (such as delta changes, or RDF payload) or a URL to a large payload in external storage. This specification will be pulled out of the QLD spatial information system and reused in other projects in the future.</p>"},{"location":"products/3rdparty/fuseki/#message-rdf-patch-log","title":"Message - RDF patch log","text":"<p>Header:     application/rdf-patch</p> <p>Description:     Raise an error. RDF patch logs require the previous patch log identifier in the patch log header. The previous patch log identifier may not be valid by the time the message is consumed and sent to the RDF Delta Server. Producers must submit RDF patch logs in the \u201cRDF patch body\u201d format.</p>"},{"location":"products/3rdparty/fuseki/#message-rdf-patch-body","title":"Message - RDF patch body","text":"<p>Header:     application/rdf-patch-body</p> <p>Description:     The mime type is informal but is required to inform consumers that the content is a valid RDF patch log body but is without the required header information. Consumers must retrieve the latest RDF patch log identifier, attach it to the current patch log header, and submit it to the RDF Delta Server. Suggested identifier regime is to generate a UUID version 4.</p>"},{"location":"products/3rdparty/fuseki/#message-rdf-turtle","title":"Message - RDF Turtle","text":"<p>Header:     text/turtle, application/n-triples, application/ld+json, etc. This should include all official triple and quad serialisation formats.</p> <p>Description:     The RDF payload is converted into an RDF patch log with all statements as \u201cappend\u201d and sent to the RDF Delta Server.</p>"},{"location":"products/3rdparty/fuseki/#message-uri-list","title":"Message - URI list","text":"<p>Header:     text/uri-list</p> <p>Description:     The message body consists of a line-separated listing of URLs of the location of the RDF patch log or payload. The consumer performs a request to each URL, processes it, and submits it to the RDF Delta Server.</p> <p>Note: This specification is currently incomplete. Ideally the header also contains metadata about the kind of mime type of each URL. It may be a requirement that all documents at each URL must be compressed using a specific compression algorithm  to reduce data transfer bandwidth.</p>"},{"location":"products/3rdparty/fuseki/#message-sparql-update","title":"Message - SPARQL Update","text":"<p>Header:     application/sparql-update</p> <p>Description:     A SPARQL Update query. The consumer must send this to the Fuseki SPARQL Update endpoint, which will update the Fuseki database state, and propagate the changes back to the RDF Delta Server.</p>"},{"location":"products/prez/","title":"Prez Overview","text":"<p>Prez is a data-configurable Linked Data API that delivers profiles of Knowledge Graph data according to the Content Negotiation by Profile standard.</p> <p>Prez is used to publish:</p> <ul> <li>lists of managed vocabularies</li> <li>catalogues of digital resources - highly configurable</li> <li>spatial reference datasets</li> </ul> <p>While being open source, Prez is mostly maintained by KurrawongAI who provide professional services to assist with its use.</p> <p>Where's the UI?</p> <p>Prez delivers data only - usually RDF but also GeoJSON, XML etc. - and it delivers a special form of its data which includes all the labels needed for human-readable display.</p> <p>If you want a UI that can render data as HTML and other fancy graphical widgets, see Prez UI.</p> <p>Other UIs can be made for Prez too: you don't only have to use PrezUI.</p>"},{"location":"products/prez/#contents","title":"Contents","text":"<ul> <li>Demo</li> <li>Installation</li> <li>Configuration</li> <li>Running</li> <li>Redirect Service</li> <li>Data Validation</li> <li>Contact</li> <li>Contributing</li> <li>License</li> </ul>"},{"location":"products/prez/#demo","title":"Demo","text":"<p>We maintain a demonstration instance of Prez + PrezUI online at:</p> <p>https://demo.dev.kurrawong.ai</p> <p>There you will see a system delivering multiple catalogues of demonstration content and real content from projects re-delivered here for testing. </p> <p>Browse that system's catalogues - https://demo.dev.kurrawong.ai/catalogs - or search it - https://demo.dev.kurrawong.ai/search - to get a sense of what Prez can do.</p>"},{"location":"products/prez/#installation","title":"Installation","text":"<p>You can run Prez, PrezUI and required databases on your computer either \"directly\" - using the application's code - or you can use Docker containers we supply for each of the parts.</p> <p>To see something like the Demo prez instance running, you will need to run:</p> <ol> <li>an RDF database - we recommend Fuseki but you can use others that support SPARQL</li> <li>Prez</li> <li>PrezUI</li> </ol>"},{"location":"products/prez/#running-directly","title":"Running directly","text":""},{"location":"products/prez/#fuseki","title":"Fuseki","text":"<p>See running Fuseki.</p>"},{"location":"products/prez/#prez","title":"Prez","text":"<p>To get a copy of Prez on your computer, run:</p> <pre><code>git clone https://github.com/RDFLib/prez\n</code></pre> <p>Prez is developed with Poetry, a Python packaging and dependency tool.</p> <p>Poetry presents all of Prez's dependencies (other Python packages) in the <code>pyproject.toml</code> file located in the project root directory.</p> <p>To install the Python dependencies run:</p> <pre><code>poetry install\n</code></pre> <p>Note: Poetry must be installed on the system. To check if you have Poetry installed run <code>poetry --version</code>. For tips on installing and managing specific dependency groups check the documentation.</p> <p>You will need to configure Prez to \"see\" the SPARQL Endpoint delivered by Fuseki or your other RDF database. See configuration - SPARQL Endpoint below.</p>"},{"location":"products/prez/#prezui","title":"PrezUI","text":"<p>See the PrezUI Installation section.</p>"},{"location":"products/prez/#running-containers","title":"Running Containers","text":""},{"location":"products/prez/#fuseki_1","title":"Fuseki","text":""},{"location":"products/prez/#prez_1","title":"Prez","text":""},{"location":"products/prez/#prez-ui","title":"Prez UI","text":""},{"location":"products/prez/#configuration","title":"Configuration","text":"<p>The following Environment Variables can be used to configure Prez.</p> <p>Note</p> <p>In most cases all that is required to be set is the SPARQL_ENDPOINT variable.</p> <p>These can be set in a '.env' file which will get read in via python-dotenv. Alternatively, set them directly in the environment from which Prez is run.</p>"},{"location":"products/prez/#sparql-endpoint-configuration","title":"SPARQL Endpoint Configuration","text":"<ul> <li><code>sparql_endpoint</code>: Read-only SPARQL endpoint for Prez.</li> <li><code>sparql_username</code>: A username for the Prez SPARQL endpoint, if required by the RDF DB. Default is <code>None</code>.</li> <li><code>sparql_password</code>: A password for the Prez SPARQL endpoint, if required by the RDF DB. Default is <code>None</code>.</li> </ul>"},{"location":"products/prez/#network-configuration","title":"Network Configuration","text":"<ul> <li><code>protocol</code>: The protocol used to deliver Prez. Default is <code>\"http\"</code>.</li> <li><code>host</code>: Prez's host domain name. Default is <code>\"localhost\"</code>.</li> <li><code>port</code>: The port Prez is made accessible on. Default is <code>8000</code>.</li> </ul>"},{"location":"products/prez/#system-uri","title":"System URI","text":"<ul> <li><code>system_uri</code>: An IRI for the Prez system as a whole. This value appears in the landing page RDF delivered by Prez (<code>\"/\"</code>). Default is <code>f\"{protocol}://{host}:{port}\"</code>.</li> </ul>"},{"location":"products/prez/#logging-configuration","title":"Logging Configuration","text":"<ul> <li><code>log_level</code>: Logging level. Default is <code>\"INFO\"</code>.</li> <li><code>log_output</code>: Logging output destination. Default is <code>\"stdout\"</code>.</li> </ul>"},{"location":"products/prez/#prez-metadata","title":"Prez Metadata","text":"<ul> <li><code>prez_title</code>: Title for the Prez instance. Default is <code>\"Prez\"</code>.</li> <li><code>prez_desc</code>: Description of the Prez instance. Default is a description of the Prez web framework API.</li> <li><code>prez_version</code>: Version of the Prez instance. Default is <code>None</code>.</li> </ul>"},{"location":"products/prez/#curie-separator","title":"CURIE Separator","text":"<ul> <li><code>curie_separator</code>: Separator used in CURIEs. Default is <code>\":\"</code>. This separator appears in links generated by Prez, and in turn in URL paths.</li> </ul>"},{"location":"products/prez/#ordering-and-predicate-configuration","title":"Ordering and Predicate Configuration","text":"<ul> <li><code>order_lists_by_label</code>: Whether to order lists by label. Default is <code>True</code>.</li> </ul>"},{"location":"products/prez/#label-predicates","title":"Label Predicates","text":"<p>Used for displaying RDF with human readable labels. - <code>label_predicates</code>: List of predicates used for labels. Default includes:     - <code>skos:prefLabel</code>     - <code>dcterms:title</code>     - <code>rdfs:label</code>     - <code>sdo:name</code></p> <p>When an annotated (<code>+anot</code>) mediatype is used, Prez includes triples for every URI in the initial response which has one of the above properties. These annotation triples are then cached. The annotations are used for display purposes, for example HTML pages. </p>"},{"location":"products/prez/#description-predicates","title":"Description Predicates","text":"<p>Similar to label predicates above. - <code>description_predicates</code>: List of predicates used for descriptions. Default includes:     - <code>skos:definition</code>     - <code>dcterms:description</code>     - <code>sdo:description</code></p>"},{"location":"products/prez/#provenance-predicates","title":"Provenance Predicates","text":"<p>Similar to provenance predicates above. - <code>provenance_predicates</code>: List of predicates used for provenance. Default includes:     - <code>dcterms:provenance</code></p>"},{"location":"products/prez/#other-predicates","title":"Other Predicates","text":"<p>The annotation mechanism can further be used to generally return certain properties wherever present. - <code>other_predicates</code>: List of other predicates. Default includes:     - <code>sdo:color</code>     - <code>reg:status</code>     - <code>skos:narrower</code>     - <code>skos:broader</code></p>"},{"location":"products/prez/#sparql-repository-configuration","title":"SPARQL Repository Configuration","text":"<ul> <li><code>sparql_repo_type</code>: Type of SPARQL repository. Default is <code>\"remote\"</code>. Options are <code>\"remote\"</code>, <code>\"pyoxigraph\"</code>, and <code>\"oxrdflib\"</code></li> <li><code>sparql_timeout</code>: Timeout for SPARQL queries. Default is <code>30</code>.</li> </ul>"},{"location":"products/prez/#contact-information","title":"Contact Information","text":"<ul> <li><code>prez_contact</code>: Contact information for Prez. Default is <code>None</code>.</li> </ul>"},{"location":"products/prez/#prefix-generation","title":"Prefix Generation","text":"<ul> <li><code>disable_prefix_generation</code>: Whether to disable prefix generation. It is recommended to disable prefix generation for large data repositories, further, it is recommended to always specify prefixes in the <code>prez/reference_data/prefixes/</code> directory. Default is <code>False</code>.</li> </ul>"},{"location":"products/prez/#language-and-search-configuration","title":"Language and Search Configuration","text":"<ul> <li><code>default_language</code>: Default language for Prez. Default is <code>\"en\"</code>.</li> <li><code>default_search_predicates</code>: Default search predicates. Default includes:<ul> <li><code>rdfs:label</code></li> <li><code>skos:prefLabel</code></li> <li><code>sdo:name</code></li> <li><code>dcterms:title</code></li> </ul> </li> </ul>"},{"location":"products/prez/#local-rdf-directory","title":"Local RDF Directory","text":"<p>Used in conjunction with the Pyoxigraph repo. Specifies a directory (from the repository root) to load into the Pyoxigraph in memory data graph. Not used for other repository types. - <code>local_rdf_dir</code>: Directory for local RDF files. Default is <code>\"rdf\"</code>.</p>"},{"location":"products/prez/#endpoint-structure","title":"Endpoint Structure","text":"<ul> <li><code>endpoint_structure</code>: Default structure of the endpoints, used to generate links. Default is <code>(\"catalogs\", \"collections\", \"items\")</code>.</li> </ul>"},{"location":"products/prez/#system-endpoints","title":"System Endpoints","text":"<ul> <li><code>system_endpoints</code>: List of system endpoints. Default includes:<ul> <li><code>ep:system/profile-listing</code></li> <li><code>ep:system/profile-object</code></li> </ul> </li> </ul>"},{"location":"products/prez/#running","title":"Running","text":"<p>This section is for developing Prez locally. See the Running options below for running Prez in production.</p> <p>To run the development server (with auto-reload on code changes):</p> <pre><code>poetry run python main.py\n</code></pre>"},{"location":"products/prez/#running-in-a-container","title":"Running in a Container","text":"<p>Prez container images are built using a Github Action and are available here.</p> <p>The Dockerfile in the repository can also be used to build a Docker image.</p>"},{"location":"products/prez/#image-variants","title":"Image variants","text":"<p>The image name is <code>ghcr.io/rdflib/prez</code>.</p> <p>The <code>latest</code> tag points to the latest stable release of Prez. All latest stable releases have a major, major and minor, and major, minor and patch tag pointing to it.</p> <p>For example, for a release with a git tag of 3.2.4, the following tags will be on the container image:</p> <ul> <li><code>3</code></li> <li><code>3.2</code></li> <li><code>3.2.4</code></li> <li><code>latest</code></li> </ul> <p>New commits to the <code>main</code> branch creates a rolling dev image with the <code>dev</code> tag. The dev builds will also include a tag in the form of major.minor.{patch+1}-dev.{commits-since-last-release}.{short-commit-sha}. This conforms to semantic versioning and will be recognised by orchestration systems to perform automatic releases.</p> <p>For example, if the latest release is 3.2.4 and there have been 7 new commits since the release and the short commit SHA is fc82562, then the container image tag will be:</p> <ul> <li><code>3.2.5-dev.7.fc82562</code></li> </ul> <p>To run the pulled docker image:</p> <pre><code>docker run -p 8000:8000 \\\n    -e SPARQL_ENDPOINT=&lt;your_sparql_endpoint&gt; \\\n    &lt;your_image_id&gt;\n</code></pre> <p>The above command starts a Docker container running Prez on port 8000, connected to the specified sparql endpoint.</p>"},{"location":"products/prez/#testing","title":"Testing","text":"<p>Prez uses PyTest and Coverage for testing and test coverage reports.</p> <p>To run all available tests:</p> <pre><code>poetry run pytest tests\n</code></pre> <p>To run all available tests for coverage analysis:</p> <pre><code>poetry run coverage run -m pytest tests\n</code></pre> <p>To generate a coverage report:</p> <pre><code>poetry run coverage report\n</code></pre>"},{"location":"products/prez/#redirect-service","title":"Redirect Service","text":"<p>As a Linked Data server, Prez provides a redirect service at <code>/identifier/redirect</code> that accepts a query parameter <code>iri</code>, looks up the <code>iri</code> in the database for a <code>foaf:homepage</code> predicate with a value, and if it exists, return a redirect response to the value.</p> <p>This functionality is useful for institutions who issue their own persistent identifiers under a domain name that they control. The mapping from the persistent identifier to the target web resource is stored in the backend SPARQL store.</p> <p>This is an alternative solution to persistent identifier services such as the w3id.org. In some cases, it can be used together with such persistent identifier services to avoid the need to provide the redirect mapping in webserver config (NGINX, Apache HTTP, etc.) and instead, define the config as RDF data.</p>"},{"location":"products/prez/#data-validation","title":"Data Validation","text":"<p>For Prez to deliver data via its various subsystems, the data needs to conform to some minimum requirements: you can't, for instance, run VocPrez without any SKOS ConceptSchemes defined!</p>"},{"location":"products/prez/#validation","title":"Validation","text":"<p>All the profiles listed above provide validators that can be used with RDF data to test to see if it's valid. If it is, Prez will be just fine with it.</p> <p>The profiles' validators are all available from the profiles themselves (navigate to the listings of other profile resources via the specification links above) and they are also loaded into the RDFTools online tool which you can use without downloading or installing anything:</p> <ul> <li>http://rdftools.kurrawong.net/validate</li> </ul> <p>Look for the VocPrez Compounded and similar validators. The 'compounded' bit means that validator will validate data against all VocPrez and inherited requirements.</p>"},{"location":"products/prez/#contact","title":"Contact","text":"<p>NOTE: This open source tool is actively developed and supported by KurrawongAI, a small Australian Knowledge Graph company, developers at the University of Melbourne and by open source contributors too.</p> <p>To flag problems or raise questions, please create issues in the Issue Tracker or you can contact developers using their details below.</p> <p>Here are the lead developers:</p> <p>KurrawongAI - David Habgood - david@kurrawong.ai - Nicholas Car - nick@kurrawong.ai - Edmond Chuc - edmond@kurrawong.ai</p> <p>University of Melbourne - Prez UI mainly - Jamie Feiss - jamie.feiss@unimelb.edu.au</p>"},{"location":"products/prez/#contributing","title":"Contributing","text":"<p>We love contributions to this tool and encourage you to create Issues in this repository's Issue Tracker or to submit a Pull Request!</p> <p>There is documentation on contributing to Prez, see Developer Information.</p>"},{"location":"products/prez/#license","title":"License","text":"<p>This version of Prez and the contents of this repository are also available under the BSD-3-Clause License.</p>"},{"location":"products/prez/data-preparation/","title":"Preparing Data for Display in Prez","text":""},{"location":"products/prez/data-preparation/#prez-fuseki-prezui","title":"prez #fuseki #prezui","text":"<p>When loading your data into a triple store for display in Prez there are some steps that you can take in preparation to make the experience as smooth as possible.</p> <p>The following steps describe the recommended way to prepare your data for loading to into the Prez system.</p> <ol> <li> <p>Arrange the data into two folders.</p> <ol> <li> <p>data and metadata</p> <p>The data and metadata folder is all the RDF that makes up your dataset. This includes resource definitions, containers, collections, vocabularies, ontologies, catalogs, etc. It is the data that you actually want to load into the Prez system.</p> <p>This folder can have subfolders to logically group the data. The important part is just to seperate the main data from any required annotations or background data (discussed in the next bullet point).</p> <p>Typically, you would have a hierarchy of resources, such as for a vocabulary</p> <pre><code>dcat:Catalog\n    \u2937 (dcterms:hasPart) skos:ConceptScheme\n        \u2937 (skos:hasTopConcept) skos:Concept\n</code></pre> <p>The data and metadata folder should contain declarations and definitions for all these resources.</p> </li> <li> <p>background annotations</p> <p>The background folder contains labels and descriptions for resources that are referenced but not defined in the data you want to load. For example, you may have be using the made up dog ontology to declare that</p> <pre><code>dog:fifi dog:tailWaggingStyle \"vigorous\" .\n</code></pre> <p>But you haven't -and have no intention of- defining a label for the <code>dog:tailWaggingStyle</code> predicate. In this case, the label is defined externally (in the <code>dog</code> ontology) and we just need to include the label so that the predicate can be displayed neatly in Prez, but we don't need to include the whole ontology.</p> <p>In this case a declaration such as</p> <pre><code>dog:tailWaggingStyle rdfs:label \"Tail wagging style\" .\n</code></pre> <p>Should be added to the background annotations folder.</p> <p>NOTE Prez includes some annotations out of the box. You can see which annotations are included by checking here.</p> <p>These annotations are taken from the semantic background. A public repository of annotations for most of the major public ontologies.</p> <p>IMPORTANT The reason for separating out the annotations like this is so that you can feed them into a tool like Labelify as 'context' when checking for missing labels. It also allows you to easily load background data into a separate  named graph which is often a useful strategy.</p> </li> </ol> </li> <li> <p>Validate the data</p> <p>It's always a good idea to ensure that the data is valid before trying to load it. This will save time and catch errors early.</p> <p>There are a selection of tools available that can be used to validate RDF data. For an easy to use web based validator, check out SHACL Validator. It can be used to check if your RDF is syntactically valid, and enforce that your data conforms that any SHACL rules that may apply. Note that if no SHACL shapes are provided then the tool will just validate the RDF.</p> </li> <li> <p>Check for missing labels</p> <p>As mentioned above when loading data into Prez it is important to ensure that all resources are properly annotated, otherwise they cannot be rendered nicely in the UI.</p> <p>To see which labels are missing from your data you can use Labelify. An online RDF labelling tool that can help you easily identify any missing labels.</p> <p>Remember that Prez includes annotations for most major ontologies out of the box, so you don't need to include those again.</p> </li> <li> <p>Complete</p> <p>You should now be able to load data into Prez and have it nicely presented. For troubleshooting and common gotchas check the FAQ.</p> </li> </ol>"},{"location":"products/prez/data-preparation/#faq","title":"FAQ","text":"<ul> <li>...</li> </ul>"},{"location":"products/prez/developers/","title":"Developer Information","text":"<p>This documentation is to assist developers of Prez, not users or installers.</p> <ul> <li>Profiles<ul> <li>General profile specification</li> <li>Specification of Mediatypes and Resource Formats</li> <li>Classes for a Profile</li> <li>Default profiles</li> <li>Direct Paths</li> <li>Sequence Paths</li> <li>Inverse Paths</li> <li>Combinations of paths</li> <li>Excluded and Optional paths</li> <li>Blank Nodes</li> <li>Profile and mediatype selection logic</li> </ul> </li> <li>Focus Node Selection<ul> <li>High level summary</li> <li>Detail</li> </ul> </li> <li>Content delivered by Prez</li> <li>Internal links<ul> <li>Link generation</li> </ul> </li> <li>Generating Prefixes</li> <li>Annotation properties</li> <li>How to add an endpoint</li> <li>Query Generation</li> <li>Repositories</li> <li>Startup Routine</li> <li>High Level Sequence <code>/object</code> endpoint</li> <li>High Level Sequence listing and individual object endpoints</li> </ul>"},{"location":"products/prez/developers/#profiles","title":"Profiles","text":"<p>SHACL NodeShapes and PropertyShapes are utilised to determine which properties of Focus Nodes should be rendered.</p>"},{"location":"products/prez/developers/#general-profile-specification","title":"General profile specification","text":"<p>Each Profile must have the following properties: - A <code>prof:Profile</code> type - A type of either <code>prez:ObjectProfile</code> (for rendering objects) or <code>prez:ListingProfile</code> (for rendering lists of objects), or both. - A title, identifier (with datatype xsd:token), and description, using the DCTERMS namespace.</p>"},{"location":"products/prez/developers/#specification-of-mediatypes-and-resource-formats","title":"Specification of Mediatypes and Resource Formats","text":"<p>Extensions to SHACL are used to specify the mediatypes and resource formats available for a given profile. These are specified as follows. The namespace used is http://www.w3.org/ns/dx/connegp/altr-ext#, and the prefix used for this namespace is <code>altr-ext</code>.</p>"},{"location":"products/prez/developers/#resource-formats","title":"Resource formats","text":"<p>The default resource format for a profile can be set with <code>altr-ext:hasDefaultResourceFormat</code>. For example: <pre><code>prez:OGCSchemesObjectProfile  \n    a prof:Profile , prez:ObjectProfile , sh:NodeShape ;\n    altr-ext:hasDefaultResourceFormat \"text/turtle\" ;\n.\n</code></pre> The available resource formats for a profile can be set with <code>altr-ext:hasResourceFormat</code>. For example: <pre><code>prez:OGCSchemesObjectProfile  \n    a prof:Profile , prez:ObjectProfile , sh:NodeShape ;\n    altr-ext:hasResourceFormat \"text/turtle\" , \"application/ld+json\" ;\n</code></pre></p>"},{"location":"products/prez/developers/#classes-for-a-profile","title":"Classes for a Profile","text":"<p>The classes of object which a profile constrains can be specified with <code>altr-ext:constrainsClass</code>. Prez utilises this information when determining whether a requested profile can be used; and the alternate profiles that are available to render a resource. An example is given below: <pre><code>prez:OGCSchemesObjectProfile  \n    a prof:Profile , prez:ObjectProfile , sh:NodeShape ;\n    altr-ext:constrainsClass dcat:Catalog ;\n.\n</code></pre></p>"},{"location":"products/prez/developers/#default-profiles","title":"Default profiles","text":"<p>A default profile can be specified using the <code>altr-ext:hasNodeShape</code> and <code>altr-ext:hasDefaultProfile</code> predicates. This is typically done on an \"umbrella\" profile which indicates default profiles for all classes the API can render. An example is given below: <pre><code>prez:OGCRecordsProfile\n    a prof:Profile ;\n    dcterms:identifier \"ogc\"^^xsd:token ;\n    dcterms:description \"A system profile for OGC Records conformant API\" ;\n    dcterms:title \"OGC Profile\" ;\n    altr-ext:constrainsClass prez:CatPrez ;\n    altr-ext:hasDefaultResourceFormat \"text/anot+turtle\" ;\n    altr-ext:hasNodeShape [\n        a sh:NodeShape ;\n        sh:targetClass prof:Profile , dcat:Catalog , dcat:Resource , skos:Concept , geo:Feature , geo:FeatureCollection\n                               , skos:Collection , rdf:Resource , prez:SearchResult , prez:CQLObjectList ;\n        altr-ext:hasDefaultProfile prez:OGCListingProfile\n    ] , [\n        a sh:NodeShape ;\n        sh:targetClass skos:ConceptScheme ;\n        altr-ext:hasDefaultProfile prez:OGCSchemesListProfile\n    ] , [\n        a sh:NodeShape ;\n        sh:targetClass skos:ConceptScheme ;\n        altr-ext:hasDefaultProfile prez:OGCSchemesObjectProfile\n    ] , [\n        a sh:NodeShape ;\n        sh:targetClass prof:Profile , dcat:Catalog , dcat:Resource , skos:Concept , geo:Feature , geo:FeatureCollection\n                               , skos:Collection , rdf:Resource ;\n        altr-ext:hasDefaultProfile prez:OGCItemProfile\n    ]\n    .\n</code></pre> Note the target classes are shared across both listings of items, and items themselves; the API determines whether a listing or object profile is appropriate based on the endpoint a request is received at.</p>"},{"location":"products/prez/developers/#direct-paths","title":"Direct Paths","text":"<p>Direct properties of a focus node are specified via <code>sh:path</code>.</p> <p>Example: <pre><code>sh:property [  \n    sh:path prov:qualifiedDerivation  \n    ]\n</code></pre></p> <p>A convenience predicate is provided to specify the inclusion of all predicates, <code>shext:allPredicateValues</code>.</p> <p>Example: <pre><code>sh:property [  \n    sh:path shext:allPredicateValues ;  \n    ]\n</code></pre></p>"},{"location":"products/prez/developers/#sequence-paths","title":"Sequence Paths","text":"<p>Sequence paths are specified as property shapes with a path representing the linked list of properties from a focus node. <pre><code>sh:property [  \n    sh:path ( prov:qualifiedDerivation prov:hadRole )  \n    ]\n</code></pre></p>"},{"location":"products/prez/developers/#inverse-paths","title":"Inverse Paths","text":"<p>Inverse paths are specified on a nested blank node where the first property is <code>sh:inversePath</code>. <pre><code>sh:property [  \n    sh:path [ sh:inversePath dcterms:hasPart ] ;  \n    ]\n</code></pre></p>"},{"location":"products/prez/developers/#combinations-of-paths","title":"Combinations of paths","text":"<p>Multiple paths can be specified at once using <code>sh:union</code>. <pre><code>sh:property [  \n    sh:path (  \n        sh:union (  \n          dcterms:publisher  \n          reg:status  \n          ( prov:qualifiedDerivation prov:hadRole )  \n          ( prov:qualifiedDerivation prov:entity )  \n        )  \n      )  \n    ]\n</code></pre></p>"},{"location":"products/prez/developers/#excluded-and-optional-paths","title":"Excluded and Optional paths","text":"<p>The above property paths when specified without a min or max count must be present for a focus node to be returned. That is, by default, specified paths must be present for the focus node and properties to be returned.</p> <p>The following constructs can be used to specify excluded or optional properties.</p>"},{"location":"products/prez/developers/#exclude","title":"Exclude","text":"<p>Specification: <code>sh:maxCount 0</code> Interpretation: do not include these paths from the focus node, even if they exist in the data. Example: <pre><code>sh:property [  \n    sh:maxCount 0 ;  \n    sh:path dcterms:hasPart  \n    ]\n</code></pre></p>"},{"location":"products/prez/developers/#optional","title":"Optional","text":"<p>Specification: <code>sh:minCount 0</code> Interpretation: include these paths from the focus node if they exist. Example: <pre><code>sh:property [  \n    sh:minCount 0 ;  \n    sh:path dcterms:hasPart  \n    ]\n</code></pre></p>"},{"location":"products/prez/developers/#blank-nodes","title":"Blank Nodes","text":"<p>A convenience predicate is provided to specify the inclusion of blank nodes to a given depth, <code>shext:bnode-depth</code>. Note this is specified directly on the profile and not on a property shape as it does not relate to any particular property shape. Specification: <code>shext:bnode-depth</code> Example: <pre><code>prez:OGCSchemesObjectProfile  \n    a prof:Profile , prez:ObjectProfile , sh:NodeShape ;\n    shext:bnode-depth 2 ;\n</code></pre></p>"},{"location":"products/prez/developers/#profile-and-mediatype-selection-logic","title":"Profile and mediatype selection logic","text":"<p>The following logic is used to determine the profile and mediatype to be returned:</p> <ol> <li>If a profile and mediatype are requested, they are returned if a matching profile which has the requested mediatype is found, otherwise the default profile for the most specific class is returned, with its default mediatype.</li> <li>If a profile only is requested, if it can be found it is returned, otherwise the default profile for the most specific class is returned. In both cases the default mediatype is returned.</li> <li>If a mediatype only is requested, the default profile for the most specific class is returned, and if the requested mediatype is available for that profile, it is returned, otherwise the default mediatype for that profile is returned.</li> <li>If neither a profile nor mediatype is requested, the default profile for the most specific class is returned, with the default mediatype for that profile.</li> </ol> <p>The SPARQL query used to select the profile is given in Appendix D.</p>"},{"location":"products/prez/developers/#focus-node-selection","title":"Focus Node Selection","text":""},{"location":"products/prez/developers/#high-level-summary","title":"High level summary","text":"<p>For object endpoints, the (single) focus node is specified at runtime, either as a URL path parameter or query string argument.</p> <p>For listing endpoints, the following inputs are used to determine which nodes to select: 1. Endpoint - an endpoint is mapped to one or more endpoint SHACL NodeShapes. 2. CQL JSON - only used as filter, i.e. filters on specified predicates. 3. Search term - filters the label properties of focus nodes to a given search term. Currently a REGEX search is supported.</p> <p>All listing endpoints support these inputs. The inputs are transformed into the SPARQL Grammar, merged together, and combined with SPARQL Grammar for profiles to create a single query. Profiles specify the inclusion/exclusion of properties on focus nodes, and are detailed in \"Profile Design\".</p>"},{"location":"products/prez/developers/#detail","title":"Detail","text":"<p>Determine which nodes to select. </p> <p>This forms the inner select part of the SPARQL query. The inputs are one or more of: the URL path a query is sent to; a CQL filter expression; and a search term. The outputs are three sets of SPARQL Grammar objects <code>TriplesSameSubject</code>, <code>TriplesSameSubjectPath</code>,  and <code>GraphPatternNotTriples</code>. The <code>TriplesSameSubject</code> are used to form the <code>ConstructTriples</code> part of the query; the  <code>TriplesSameSubjectPath</code>,  and <code>GraphPatternNotTriples</code> form the <code>WhereClause</code>.</p>"},{"location":"products/prez/developers/#1-endpoint-nodeshapes","title":"1. Endpoint Nodeshapes","text":"<p>Considerations: 1. Class of objects to list (e.g. for /catalogs, list all items of class dcat:Catalog) 2. Relationship to parent objects (e.g. for /catalogs/{parent_catalog_curie}/collections/, list all items that have the relationship dcterms:hasPart from the parent catalog curie) Implementation:     SHACL shapes are used to represent the how URL path parameters are translated into a SPARQL query.     One endpoint maps to one or more endpoint NodeShapes. For example the items endpoint can render resources of type <code>skos:Concept</code> and <code>geo:Feature</code>. An example of an endpoint definition is: <pre><code>ogce:item-object  \n    a ont:ObjectEndpoint ;  \n    ont:relevantShapes ex:Feature , ex:ConceptSchemeConcept , ex:CollectionConcept , ex:Resource ;  \n.\n</code></pre></p> <p>To determine which NodeShape (under <code>ont:relevantShapes</code>) should be used to render resources, the class of parents in the URL path is first determined. The logic for this is:     1. Get the classes of all parents in the URL path. Prez caches this class information.     2. Match these to <code>sh:class</code> statements on the PropertyShapes for the NodeShape. <code>sh:class</code> is used on nested PropertyShapes to specify a constraint on the class of related nodes, that is, nodes related via the property shape. (e.g. \"the class of the first parent is <code>dcat:Resource</code>, the class of the second parent is <code>dcat:Catalog</code>, therefore the applicable NodeShape for the listing is the <code>ex:Resource</code> NodeShape.)      The NodeShape information, once determined, is used for:     1. Query generation - which class of nodes to list (e.g. <code>rdf:Resource</code> below)     2. Link generation - to determine which endpoints can render a resource of a given class, and, how to find the parents of a given object in order to generate a link (e.g. the parents are all related via <code>dcterms:hasPart</code> in the example below.)     An example NodeShapes for describing an endpoint is:</p> <pre><code>ex:Resource  \n    a sh:NodeShape ;  \n    ont:hierarchyLevel 3 ;  \n    sh:targetClass rdf:Resource ;  \n    sh:property [  \n        sh:path [ sh:inversePath dcterms:hasPart ] ;  \n        sh:class dcat:Resource ;  \n    ] , [  \n        sh:path ( [ sh:inversePath dcterms:hasPart ] [ sh:inversePath dcterms:hasPart ] );  \n        sh:class dcat:Catalog ;  \n    ] .\n</code></pre> <p>The hierarchyLevel is used to filter the set of potentially relevant NodeShapes - when a request comes from an endpoint, that endpoint has a corresponding hierarchy level.</p> <p>A  further example for the collections endpoint is provided: <pre><code>ex:Collections  \n    a sh:NodeShape ;  \n    ont:hierarchyLevel 2 ;  \n    sh:targetClass geo:FeatureCollection , skos:ConceptScheme , skos:Collection , dcat:Resource ;  \n    sh:property [  \n        sh:path [ sh:inversePath dcterms:hasPart ] ;  \n        sh:class dcat:Catalog ;  \n    ] .\n</code></pre></p> <p>This means to select the nodes of class <code>dcat:Resource</code>, <code>geo:FeatureCollection</code>, <code>skos:ConceptScheme</code>, or <code>skos:Collection</code>, which are related to a parent node of class <code>dcat:Catalog</code>, by the relationship <code>dcterms:hasPart</code>. </p>"},{"location":"products/prez/developers/#2-cql","title":"2. CQL","text":"<p>Considerations: 1. Mapping of JSON values to URIs. 2. Filtering of properties vs. graph pattern matching; the latter supports more complex operations (sequence, inverse paths etc.).  Implementation: CQL JSON expressions are translated to JSON LD to allow easy mapping to URIs. Examples are provided in the API docs using test data. A demo instance is available here. CQL JSON documentation is available here:</p> <p>Properties are assumed to be URIs. Values for properties can be specified as URIs using a JSON LD like \"@id\", for example: <pre><code>{  \n  \"op\": \"=\",  \n  \"args\": [  \n    {  \n      \"property\": \"http://www.w3.org/2000/01/rdf-schema#member\"  \n    },  \n    { \"@id\": \"http://example.com/datasets/sandgate/facilities\" }  \n  ]  \n}\n</code></pre></p> <p>The following context is \"inserted\" into CQL JSON to create \"CQL JSON-LD\". <pre><code>{  \n  \"@version\": 1.1,  \n  \"@base\": \"http://example.com/\",  \n  \"@vocab\": \"http://example.com/vocab/\",  \n  \"cql\": \"http://www.opengis.net/doc/IS/cql2/1.0/\",  \n  \"sf\": \"http://www.opengis.net/ont/sf#\",  \n  \"geo\": \"http://www.opengis.net/ont/geosparql#\",  \n  \"landsat\": \"http://example.com/landsat/\",  \n  \"ro\": \"http://example.com/ro/\",  \n  \"args\": {  \n    \"@container\": \"@set\",  \n    \"@id\": \"cql:args\"  \n  },  \n  \"property\": {  \n    \"@type\": \"@id\",  \n    \"@id\": \"cql:property\"  \n  },  \n  \"op\": {  \n    \"@id\": \"cql:operator\"  \n  },  \n  \"type\": {  \n    \"@id\": \"sf:type\"  \n  }  \n}\n</code></pre></p> <p>The following has been implemented: 1. Spatial functions 2. String pattern matching 3. Property filtering</p> <p>The following has not yet been implemented: 1. Time filtering</p>"},{"location":"products/prez/developers/#3-search-query","title":"3. Search query","text":"<p>Implementation: The search term is inserted into three different regex expressions which match the search term in different ways, and weights the results. A full search query is generated, and then relevant parts are extracted (<code>TriplesSameSubject</code> etc. as listed above), to generate a final query.</p> <p>Prez utilises the sparql-grammar-pydantic library to generate SPARQL queries.</p>"},{"location":"products/prez/developers/#content-delivered-by-prez","title":"Content delivered by Prez","text":"<p>Prez returns: - RDF data for specified objects - RDF data for lists of objects - Annotated RDF for specified objects - Annotated RDF for lists of objects - Available Profiles - An alternates profile for every object or listing, listing all available profiles and mediatypes - OpenAPI documentation for the API</p> <p>* Annotated RDF is RDF which includes labels, descriptions, explanatory, and other properties for all RDF terms. The predicates Prez looks for are rdfs:label, <code>dcterms:description</code>, and <code>dcterms:provenance</code>. The list of predicates Prez looks for can be extended in the profiles.</p>"},{"location":"products/prez/developers/#internal-links","title":"Internal links","text":"<p>The objects Prez delivers RDF for have URIs that uniquely identify them. Prez delivers RDF for these objects at URLs on the web. These URLs and URIs are not required to be the same, and frequently are not. For objects that Prez holds information for, it is helpful if Prez tells users the URL of these when they are referenced elsewhere in the API. This is in two places: 1. Listings of objects, for example <code>dcat:Catalog</code> at the <code>/catalogs</code> endpoint; and 2. Links to related objects, where the API holds information on the related object.\\ In these cases, in the annotated RDF mediatype (<code>text/anot+turtle</code>) URL paths are provided which link to the related object.</p> <p>For cases where URIs and URLs for a given object differ, URL redirection can be used to send users to the Prez URL instance which displays information for the object.</p>"},{"location":"products/prez/developers/#link-generation","title":"Link generation","text":"<p>Internal links use CURIEs. Prez uses the default RDFLib prefixes, covering common namespaces. Additional prefixes can be specified using the Vann ontology property \"vann:preferredNamespacePrefix\". These can be added to turtle files in the prez/reference_data/prefixes directory. Any turtle files in this directory will be loaded on startup.</p> <p>When Prez encounters a URI which is required for an internal link but is not in the current known prefixes, it will generate a prefix using the following logic: 1. Get the \"second to last part\" of the URI; either the part before a fragment if it exists, or the second to last path segment otherwise. 2. If this second to last part is less than six characters, use it as is, else: 3. Remove vowels from the second to last part and use this as the prefix. 4. If this prefix fails to bind for any reason, use RDFLib's default \"ns1\", \"ns2\" etc. prefixes.</p> <p>To get \"sensible\" or \"nice\" prefixes, it is recommended to add all prefixes which will be required to turtle files in prez/reference_data/prefixes. A future change could allow the prefixes to be specified alongside data in the backend, as profiles currently can be.</p>"},{"location":"products/prez/developers/#generating-prefixes","title":"Generating Prefixes","text":"<p>The following SPARQL query can be used as a starting point to check if a namespace prefix is defined for instances of the main classes prez delivers. NB this query should NOT be run against SPARQL endpoints for large datasets; offline options should instead be used. NB. for \"short\" URIs, i.e. a hostname with no fragments and a \"no\" path, this query will (correctly, but uselessly) return \"http://\" or \"https://\". You will need to otherwise identify what these URIs are and provide prefixes for them should you wish. <pre><code>PREFIX skos: &lt;http://www.w3.org/2004/02/skos/core#&gt;\nPREFIX vann: &lt;http://purl.org/vocab/vann/&gt;\nPREFIX dcat: &lt;http://www.w3.org/ns/dcat#&gt;\nPREFIX geo: &lt;http://www.opengis.net/ont/geosparql#&gt;\n\nSELECT DISTINCT ?namespace\n{?uri a ?type\n  BIND (REPLACE(STR(?uri), \"(.*[/#])[^#/]*$\", \"$1\") AS ?namespace)\n  VALUES ?type { skos:Collection skos:ConceptScheme skos:Concept dcat:Dataset geo:FeatureCollection geo:Feature dcat:Resource dcat:Catalog }\n  MINUS {?namespace vann:preferredPrefix ?prefix .}\n} LIMIT 100\n</code></pre></p>"},{"location":"products/prez/developers/#annotation-properties","title":"Annotation properties","text":"<p>Prez recognises the following kinds of annotation properties, and can return RDF, either via SPARQL queries, or the endpoints as annotated RDF.</p> <p>When an annotated mediatype is requested (e.g. <code>text/anot+turtle</code>), Prez will look for the following predicates for every RDF term in the (initial) response returned by the triplestore. That is it will expand the response to include the annotations and return the RDF merge of the original response and the annotations.</p> <p>Additional predicates can be added to the list of predicates Prez looks for in the profiles by adding these predicates to the configuration.</p>"},{"location":"products/prez/developers/#how-to-add-an-endpoint","title":"How to add an endpoint","text":"<p>New endpoints can be added to Prez by adding RDF, and minimal addition of FastAPI decorators.</p> <ol> <li>Add FastAPI decorator,<ol> <li>For Listing endpoints, add these to the <code>listings</code> function in <code>prez/routers/ogc_router</code>. An example is: <pre><code>@router.get(  \n    \"/catalogs\",  \n    summary=\"Catalog Listing\",  \n    name=OGCE[\"catalog-listing\"],  \n    responses=responses  \n)\n</code></pre></li> </ol> </li> </ol> <p>See the references in the code for what should be provided for <code>responses</code> and <code>openapi_extra</code>; these fields are optional but useful for documentation. The name is required, and should be a URI. 2. An endpoint definition.      1. The endpoint URI must match the name uri in the decorator.      2. The endpoint must be declared a <code>ont:ListingEndpoint</code> or <code>ont:ObjectEndpopint</code>, as Prez uses different application code to render results for these two types of endpoint.     These are in <code>prez/reference_data/endpoints/endpoint_metadata.ttl</code>. An example is: <pre><code>ogce:catalog-listing  \n    a ont:ListingEndpoint ;  \n    ont:relevantShapes ex:Catalogs ;  \n.\n</code></pre> 3.  A NodeShape for the endpoint. This describes how nodes should be selected at the given endpoint. An example is: <pre><code>ex:Catalogs  \n    a sh:NodeShape ;  \n    ont:hierarchyLevel 1 ;  \n    sh:targetClass dcat:Catalog ;  \n    sh:property [  \n        sh:path dcterms:hasPart ;  \n        sh:or (  \n            [ sh:class dcat:Resource ]  \n            [ sh:class geo:FeatureCollection ]  \n            [ sh:class skos:ConceptScheme ]  \n            [ sh:class skos:Collection ]  \n        ) ;  \n    ] .\n</code></pre></p> <p>This specifies the selection of focus nodes of class <code>dcat:Catalog</code> which have the relationship <code>dcterms:hasPart</code> to one or more of the listed classes.</p>"},{"location":"products/prez/developers/#query-generation","title":"Query Generation","text":"<p>Prez utilises the sparql-grammar-pydantic library to generate SPARQL queries.</p>"},{"location":"products/prez/developers/#focus-nodes","title":"Focus nodes","text":"<p>For objects, the focus node is specified in a query path as a curie, or in the case of the <code>/object</code> endpoint, as query parameter with the key \"uri\".</p> <p>For lists of objects, the focus node is a variable, fixed within prez to <code>?focus_node</code>.</p> <p>Usage: The focus node is substituted into the main query.</p>"},{"location":"products/prez/developers/#main-query-generation","title":"Main Query Generation","text":"<p>Prez creates a single main query to describe an object or listing of objects.</p> <p>The structure of the query is as follows: <pre><code>CONSTRUCT {  \n    &lt;construct_triples + construct_tss_list&gt;\n}  \nWHERE {  \n    # for listing queries only:    \n    { \n        SELECT ?focus_node &lt;innser_select_vars&gt;        \n        WHERE {            \n            &lt;inner_select_tssp_list&gt;            \n            &lt;inner_select_gpnt&gt;        \n            }        \n        ORDER BY &lt;order_by_direction&gt;(&lt;order_by&gt;)        \n        LIMIT &lt;limit&gt;        \n        OFFSET &lt;offset&gt;    \n    }\n    # for all queries:    \n    &lt;profile_triples&gt;    \n    &lt;profile_gpnt&gt;\n}\n</code></pre></p>"},{"location":"products/prez/developers/#construct_triples-and-construct_tss_list","title":"construct_triples and construct_tss_list","text":"<p>The triples to construct. This is taken from the union of: 1. Profile_Triples (directly) - i.e. any triple specified in the where clause will be constructed 2. Any triples within the Profile_GPNTs object. Prez utilises a convenience function provided by the SPARQL Grammar library which recursively extracts all triples within a given SPARQL Grammar object. 3. Additional_Construct_Triples (directly) - these may come from a search query, such as the query result weights, etc. </p>"},{"location":"products/prez/developers/#profile_triples-and-profile_gpnts","title":"profile_triples and profile_GPNTs","text":"<p>There is one source of profile triples and profile GPNTs - these are derived from SHACL node and property shapes associated with the selected profile (returned by ConnegP).</p> <p>At a conceptual level these profile shapes represent the \"properties\" or \"attributes\" to be returned for each focus node. At present the following SHACL expressions are covered: - minCount = 0 (optional property) - maxCount = 0 (exclude property) - path - sequence path - inverse path - class - blank nodes to a specified depth How to specify these is detailed in the Profile Design section.</p>"},{"location":"products/prez/developers/#inner_select_triples-and-inner_select_gpnts","title":"Inner_Select_Triples and Inner_Select_GPNTs","text":"<p>Inner Select Triples and Inner Select GPNTs are taken from the union of: 1. CQL 2. Search queries 3. Endpoint Nodeshapes These are detailed in the Focus Node Selection section.</p>"},{"location":"products/prez/developers/#annotations","title":"Annotations","text":"<ul> <li>Where an annotated mediatype is requested, Prez returns any annotations it can find from all available repositories (data, systems, and annotations reposoitory).</li> <li>These annotations are then cached against the URI they are for.</li> <li>The caching utilises aiocache. <ul> <li>aiocache is currently set up with in memory caches. It could be extended to utilise Redis.</li> </ul> </li> </ul> <p>A sequence diagram is shown for annotation retrieval: <pre><code>sequenceDiagram\n    Client -&gt;&gt; FastAPI: Request for data with annotated mediatype\n    FastAPI -&gt;&gt; Repo: send_queries(object/list query)\n    Repo --&gt;&gt; FastAPI: initial response graph\n    FastAPI -&gt;&gt; FastAPI: get URIs in initial response\n    FastAPI -&gt;&gt; Cache: check cache for annotations\n    Cache --&gt;&gt; FastAPI: return cached annotations (if any)\n    FastAPI -&gt;&gt; FastAPI: determine cached and uncached URIs\n    FastAPI -&gt;&gt; Repo: query for uncached annotations\n    Repo --&gt;&gt; FastAPI: return cached annotations (if any)\n    FastAPI -&gt;&gt; Cache: cache previously uncached annotations\n    FastAPI -&gt;&gt; Client: return initial response graph + annotations</code></pre></p> <p>Annotations are returned with one of the following mapped prez namespaced URIs.</p> <p>prez:label: skos:prefLabel,  dcterms:title,  rdfs:label,  sdo:name prez:description: skos:definition,  dcterms:description,  sdo:description prez:provenance: dcterms:provenance</p>"},{"location":"products/prez/developers/#repositories","title":"Repositories","text":"<p>An abstraction over data providers is provided with \"Repositories\". Three types are supported; Pyoxigraph (in memory), Oxrdflib, and RemoteSparql.  1. Data repository - one of Pyoxigraph, Oxrdflib, or RemoteSparql 2. System repository - Pyoxigraph 3. Annotations repository - Pyoxygraph</p>"},{"location":"products/prez/developers/#startup-routine","title":"Startup Routine","text":"<ol> <li>Check the SPARQL endpoints can be reached. A blank query (<code>ASK {}</code>) is used to test this. The SPARQL endpoints are not health checked post startup.</li> <li>Create in memory profile, prefix, and endpoint graphs, containing all profiles in the <code>prez/profiles</code> directory, and any additional profiles available in the triplestore (declared as a <code>http://www.w3.org/ns/dx/prof/Profile</code>)</li> <li>Look for predefined object counts in the triplestore.</li> </ol>"},{"location":"products/prez/developers/#high-level-sequence-object-endpoint","title":"High Level Sequence <code>/object</code> endpoint","text":""},{"location":"products/prez/developers/#prez-ui-or-similar-human-actionable-client","title":"Prez UI or similar human-actionable client","text":"<p>Prez provides a <code>/object</code> endpoint as an endpoint that supplies any information known about a given URI. If an annotated mediatype is requested, prez will additionally provide all system links for endpoints which can render the object. The high level sequence for this endpoint is as follows:</p> <ol> <li>Get the URI for the object from the query string</li> <li>Get the class(es) of the object from the triplestore</li> <li>Use prez's reference data for endpoints to determine which endpoints can render this object, and, a template for these endpoints, specifying any variables that need to be substituted (such as parent URIs).</li> <li>Get the object information from the triplestore, using an open profile, and in parallel any system information needed to construct the system links.</li> <li>Return the response</li> </ol>"},{"location":"products/prez/developers/#high-level-sequence-listing-and-individual-object-endpoints","title":"High Level Sequence listing and individual object endpoints","text":"<p>Prez follows the following logic to determine what information to return, based on a profile, and in what mediatype to return it.</p> <ol> <li>Determine the URI for an object or listing of objects:</li> <li>For objects:    Directly supplied through the /object?uri= query string argument <li>From the URL path the object is requested from, for example /catalogs/. abc is a curie, which is expanded to a URI. <li>Get all classes for the object or object listing</li> <li>Determine the profile and mediatype to use for the object. This is implemented as a SPARQL query and takes into account:</li> <li>The classes of the object</li> <li>Available profiles and mediatypes</li> <li>Requested profiles and mediatypes</li> <li>Default profiles and mediatypes The logic used to determine the profile and mediatype is detailed in section x.</li> <li>Build a SPARQL query.</li> <li>Execute the SPARQL query.</li> <li>If the mediatype requested is NOT annotated RDF (<code>text/anot+turtle</code>), return the results of 5, else retrieve the annotations:</li> <li>Check Prez cache for annotations</li> <li>For terms without annotations in the cache, query the triplestore for annotations</li> <li>Cache any annotations returned from the triplestore</li> <li>Return the annotations merged with the results of the SPARQL query in step 5.</li>"},{"location":"products/prez/manifest/","title":"Prez Manifest Model","text":"<p>A Prez Manifest is an RDF file that describes and links to a set of resources that can be loaded into an RDF database for Prez to provide access to.</p> <p>To support Manifest creation and use, the following tools are provided:</p> <ol> <li>The model</li> <li>Manifest Resource Roles Vocabulary</li> <li>Validator</li> <li>Build Scripts</li> <li>Examples</li> </ol>"},{"location":"products/prez/manifest/#model","title":"Model","text":"<pre><code>graph LR\n  Manifest --1:1-N--&gt; Resource;\n  Resource --1:1--&gt; artifact;\n  Resource --1:1--&gt; role;\n  Resource --1:0-1--&gt; name;\n  Resource --1:0-1--&gt; decription;</code></pre> <p>The Manifest Model is simply a Manifest class, <code>prez:Manifest</code>, which MUST have 1 or more Resource Descriptors, <code>prof:ResourceDescriptor</code> indicated by the <code>prof:hasResource</code> predicate. </p> <p>Each Resource Descriptor MUST have exactly one <code>prof:hasArtifact</code> predicate indicating an RDF literal resource (string) giving a file path or path pattern containing the resource information, relative to the manifest.</p> <p>Each Resource Descriptor MUST also have exactly one <code>prof:hasRole</code> predicate indicating a Concept from the Manifest Resource Roles Vocabulary.</p> <p>Each Resource Descriptor MAY have a <code>schema:name</code> and/r a <code>schema:description</code> predicate indicating literal resources naming and describing it.</p> <p></p>"},{"location":"products/prez/manifest/#manifest-resource-roles-vocabulary","title":"Manifest Resource Roles Vocabulary","text":"<p>This roles vocabulary contains the allowed roles that a resource can play with respect to a Manifest.</p> <p>The IRI of this vocabulary is:</p> <ul> <li><code>https://prez.dev/ManifestResourceRoles</code><ul> <li>the vocab namespace is <code>https://prez.dev/ManifestResourceRoles/</code></li> <li>recommended namespace prefix is <code>mrr</code></li> </ul> </li> </ul> <p>Human-readable form:</p> Concept IRI Label Definition Parent <code>mrr:ContainerData</code> Container Data Data for the container, usually a Catalogue, including the identity of it and each item fo content - <code>mrr:ContentData</code> Content Data Data for the content of the container - <code>mrr:ContainerAndContentModel</code> Container &amp; Content Model The default model for the container and the content. Must be a set of SAHCL Shapes - <code>mrr:ContainerModel</code> Container Model The default model for the container. Must be a set of SAHCL Shapes <code>mrr:containerAndContentModel</code> <code>mrr:ContentModel</code> Content Model The default model for the content. Must be a set of SAHCL Shapes <code>mrr:containerAndContentModel</code> <code>mrr:CompleteContainerAndContentLabels</code> Complete Content and Container Labels All the labels - possibly indluding names, descriptions &amp; seeAlso links - for the Container and Content objects - <code>mrr:IncompleteContainerAndContentLabels</code> Incomplete Content and Container Labels Some of the labels - possibly indluding names, descriptions &amp; seeAlso links - for the Container and Content objects - <p>Machine-readable form:</p> <pre><code>\n</code></pre> <p>The IRI for automatic retrieval of this vocabulary file is: https://prez.dev/ManifestResourceRoles.</p>"},{"location":"products/prez/manifest/#validator","title":"Validator","text":"<p>This simple SHACL validator \"Shapes\" file can be used by SHACL validation software to test the validity of a Manifest RDF file with respect to this model:</p> <p>The IRI for automatic retrieval of this Shapes file is: https://prez.dev/manifest/validator.</p> <p>The recommended tools to perform validation using this Shapes file are:</p> <ol> <li>KurrawongAI's Online Validator - this Shapes file is pre-loaded</li> <li>pySHACL Python tool - for scripted validation</li> </ol>"},{"location":"products/prez/manifest/#build-scripts","title":"Build Scripts","text":""},{"location":"products/prez/manifest/#documentor","title":"Documentor","text":"<p>The <code>documentor.py</code> Python script in this documentation's repository creates a \"Prez Resources\" table in either Markdown or ASCIIDOC from a Manifest file which it validates first:</p> <ul> <li>https://github.com/Kurrawong/prez.dev/blob/main/manifest/documentation.py</li> </ul>"},{"location":"products/prez/manifest/#use","title":"Use","text":"<pre><code>usage: documentor.py [-h] [-v] [-t {markdown,asciidoc}] input\n\npositional arguments:\n  input                 File, Folder or Sparql Endpoint to read RDF from\n\noptions:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n  -t {markdown,asciidoc}, --type {markdown,asciidoc}\n                        The type of markup you want to export: Markdown or ASCCIDOC\n</code></pre>"},{"location":"products/prez/manifest/#example","title":"Example","text":"<p>Using the first example Manifest, <code>example01.ttl</code> in this too's repository and also given in the Example section below:</p> <pre><code>~$ python documentor.py example01.ttl\n</code></pre> <p>produces:</p> <pre><code>Resource | Role | Description\n--- | --- | ---\nCatalogue Definition, [`catalogue.ttl`](catalogue.ttl) | [Container Data](https://prez.dev/ManifestResourceRoles/ContainerData) | The definition of, and medata for, the container which here is a dcat:Catalog object\nContent, [`vocabs/*.ttl`](vocabs/*.ttl) | [Content Data](https://prez.dev/ManifestResourceRoles/ContentData) | skos:ConceptsScheme objects in RDF (Turtle) files in the vocabs/ folder\nProfile Definition, [`ogc_records_profile.ttl`](https://github.com/RDFLib/prez/blob/main/prez/reference_data/profiles/ogc_records_profile.ttl) | [Container &amp; Content Model](https://prez.dev/ManifestResourceRoles/ContainerAndContentModel) | The default Prez profile for Records API\nLabels file, [`_background/labels.ttl`](_background/labels.ttl) | [Complete Content and Container Labels](https://prez.dev/ManifestResourceRoles/CompleteContainerAndContentLabels) | An RDF file containing all the labels for the container content\n</code></pre> <p>which renders as:</p> Resource Role Description Catalogue Definition, <code>catalogue.ttl</code> Container Data The definition of, and medata for, the container which here is a dcat:Catalog object Content, <code>vocabs/*.ttl</code> Content Data skos:ConceptsScheme objects in RDF (Turtle) files in the vocabs/ folder Profile Definition, <code>ogc_records_profile.ttl</code> Container &amp; Content Model The default Prez profile for Records API Labels file, <code>_background/labels.ttl</code> Complete Content and Container Labels An RDF file containing all the labels for the container content"},{"location":"products/prez/manifest/#loader","title":"Loader","text":"<p>The <code>loader.py</code> Python script loads the content of a Manifest into either a single trig file (a multi-graph RDF file) or an RDF database via a SPARQL Endpoint.</p>"},{"location":"products/prez/manifest/#examples","title":"Examples","text":"<p>See the simple and always up-to-date KurrawongAI Demo Vocabularies manifest:</p> <p>Full: </p> <p>Partial: </p> <p>Invalid (second Resource Descriptor does not indicate a role) </p>"},{"location":"products/prez/ui/","title":"PrezUI","text":"<p>Page in development - check back soon</p>"},{"location":"products/prez/deploying/aws/","title":"Deploying Prez with Amazon Web Services","text":"<p>Page in development - check back soon</p>"},{"location":"products/prez/deploying/azure/appservice/","title":"Deploying Prez to Azure App Service","text":"<p>This page will show you how to deploy Prez to Azure App Service.</p> <p>The following resources will be created:</p> <pre><code>    C4Context\n      Container_Boundary(sb, \"Azure Subscription\") {\n        Container_Boundary(rg, \"Resource Group\") {\n            Boundary(asp, \"App Servie Plan\", \"resource\") {\n                Component(app1, \"Fuseki\", \"webapp\")\n                Component(app2, \"Prez\", \"webapp\")\n            }\n        }\n    }</code></pre> <p>Prez provides profiles of data from a knowledge graph, but is not a knowledge graph itself. Thus, this guide uses Apache Jena Fuseki as the knowledge graph providing data to Prez.</p>"},{"location":"products/prez/deploying/azure/appservice/#deployment-steps","title":"Deployment Steps","text":""},{"location":"products/prez/deploying/azure/appservice/#1-create-the-fuseki-web-app","title":"1. Create the Fuseki Web App","text":"<p>The official Microsoft documentation is a good place to start if you have never created a web app before. Specifically see the guide on how to create a web app from a custom container image.</p> <p>An App service Plan will be created for you to host the web app. It is recommended to use the Basic B1 tier for this demo.</p> <ol> <li>Create a new web app</li> <li> <p>Under the Container configuration section set the following values:</p> field value image source other container registries registry server URL https://ghcr.io image and tag kurrawong/fuseki-geosparql:latest startup command <code>/opt/java-minimal/bin/java -cp /opt/fuseki/fuseki-server.jar org.apache.jena.fuseki.cmd.FusekiCmd --mem /demods</code> <p>Startup command explanation:</p> <p>Execute the Java binary <code>/opt/java-minimal/bin/java</code> Pass it the classpath of the Fuseki Server jar file <code>/opt/fuseki/fuseki-server.jar</code> Pass the <code>--mem</code> flag to start with an in memory dataset called <code>/demods</code></p> </li> <li> <p>Review and create the web app.</p> </li> <li>Set the <code>WEBSITES_PORT</code> environment variable to <code>3030</code></li> </ol> <p>This tells the web app that the containerized application is listening for traffic on port 3030.    The web app can then forward incoming requests (on port 443) to the correct port.</p> <p>The following MS Learn module shows hot to set environment variables for your web app. https://learn.microsoft.com/en-us/training/modules/configure-web-app-settings/2-configure-application-settings</p> <p>Once the app is deployed you can open it in the web browser to navigate the admin interface.</p> <p>[!IMPORTANT] The default username and password for this Fuseki container is admin:admin</p>"},{"location":"products/prez/deploying/azure/appservice/#2-create-the-prez-web-app","title":"2. Create the Prez Web App","text":"<ol> <li>Create a new web app</li> <li>Reuse the App Service plan you created for the Fuseki web app</li> <li> <p>Under the Container configuration section set the following values:</p> field value image source other container registries registry server URL https://ghcr.io image and tag rdflib/prez:latest </li> <li> <p>Set the required environment variables</p> </li> </ol> Variable value SPARQL_ENDPOINT https://fuseki_app_name.azurewebsites.net/demods WEBSITES_PORT 8000 <p>You should now be able to browse the Prez web app and it will present you with a response in turtle.</p>"},{"location":"products/prez/deploying/azure/appservice/#5-complete","title":"5. Complete","text":"<p>You have now deployed Prez as a web app on Azure app service.</p>"},{"location":"products/prez/deploying/azure/appservice/#next-steps","title":"Next steps","text":"<ul> <li>Upload data to Fuseki using the admin portal,</li> <li>Explore the Prez API by browsing the <code>/docs</code> endpoint,</li> <li>Learn how to persist data to Fuseki by mounting a file share,</li> <li>Deploy Prez-UI for a graphical user interface on top of the Prez API data.</li> </ul>"},{"location":"products/tools/","title":"Tools Overview","text":"<p>This section of the knowledge base has information about a number of RDF and Semantic Web-related tools that KurrawongAI maintains. The tools are briefly described below with further information available via the links or using the navigation pane on the left. </p> <p>Some of these tools are open source, others are developed and owned by KurrawongAI. All are free to use!</p> <ol> <li>kurra - A command line tool for interactions with Fuseki databases</li> <li>labelify - Tests RDF graph elements to see if they have labels</li> <li>ogctests - An unofficial, open source, Python implementation of the Open GeoSpatial Consortium's [OGC] Java-based test suite</li> <li>Prefix Lookup - Get RDF Namespaces from Prefixes</li> <li>ProvWorkflow - Records the provenance of Python workflows in RDF </li> <li>pyLODE - An OWL ontology documentation tool using Python, based on LODE</li> <li>RDF Converter - Convert between different RDF formats</li> <li>RDF Merger - Merges RDF graphs together</li> <li>SHACL Validator - Validate RDF data against SHACL rules, using the pySHACL tool</li> <li>SPARQL Validator - Validates and formats sparql queries</li> <li>VocEdit - online SKOS vocabulary creation &amp; editing</li> <li>VocExcel - Convert Excel data to SKOS vocabularies, using templates and the VocExcel library</li> </ol>"},{"location":"products/tools/kurra/","title":"kurra Python Library","text":"<p>kurra is a Python library and command line application that provides commonly-required functionality when working with  RDF files and databases.</p> <p>This library uses the RDFLib under-the-hood to process  RDF data. It supplies functions to:</p> <ul> <li>manipulate local RDF files</li> <li>send commands to RDF databases - \"triplestores\"</li> <li>SPARQL query files or databases</li> </ul> <p>kurra has detailed documentation for installation and use at its repository's home page:</p> <ul> <li>https://github.com/Kurrawong/kurra</li> </ul> <p>Note</p> <p>kurra is a dependency of other KurrawongAI tooling, such as labelify &amp;  prez-manifest.</p>"},{"location":"products/tools/kurra/#more-info","title":"More info","text":"<ul> <li>KurrawongAI Service &gt; Tools <ul> <li>for more information on our specialised Knowledge Graph tooling support. </li> </ul> </li> </ul>"},{"location":"products/tools/labelify/","title":"labelify","text":"<p>labelify is a Python module and command line utility that identifies unlabelled resources in RDF graphs and can  extract labels for them from external resources. </p> <p>Note</p> <p>If you would like to use the labelify tool directly, we provide an online GUI for it  here. </p> <p>labelify has detailed documentation for installation and use at its repository's home page:</p> <ul> <li>https://github.com/Kurrawong/labelify</li> </ul> <p>Note</p> <p>labelify is a dependency of other KurrawongAI tooling, such as prez-manifest.</p>"},{"location":"products/tools/labelify/#more-info","title":"More info","text":"<ul> <li>KurrawongAI tools<ul> <li>for access to all our online versions of tools, including labelify</li> </ul> </li> <li>KurrawongAI Service &gt; Tools <ul> <li>for more information on our specialised Knowledge Graph tooling support. </li> </ul> </li> </ul>"},{"location":"products/tools/ogc-tests/","title":"OGC API Test Suite","text":"<p>--- unofficial ---</p> <p>Kurrawong AI maintains an unofficial, open source, Python implementation of the Open GeoSpatial Consortium's [OGC] Java based test suite.</p>"},{"location":"products/tools/ogc-tests/#what-does-it-do","title":"What does it do","text":"<p>The test suite tries to verify the compliance of an endpoint against several standards defined by the OGC. The standards define how an API should be structured as well as the content and format of the responses it returns.</p> <p>The standards are:</p> <ol> <li>Features API Part 1 Core</li> <li>Features API Part 2 CRS</li> <li>Features API Part 3 Filtering</li> <li>Features API Part 4 CRUD</li> <li>Features API Part 5 Schemas</li> <li>Records API Part 1 Core</li> </ol> <p>Note that only the Features API Part 1 Core is currently implemented.</p> <p>The official test suite for the Features API Part 1 can be found [here]((https://github.com/opengeospatial/ets-ogcapi-features10) and Part 2 here.</p>"},{"location":"products/tools/ogc-tests/#how-to-get-it","title":"How to get it","text":"<p>The test suite is available on PyPi, and can be installed in the usual way.</p> <pre><code>$ python -m pip install ogctests\n</code></pre>"},{"location":"products/tools/ogc-tests/#how-to-run-it","title":"How to run it","text":"<p>Instructions on how to run the test suite are available on PyPi and GitHub.</p>"},{"location":"products/tools/ogc-tests/#why-make-another-one","title":"Why make another one","text":"<p>This test suite was designed to be used internally at KurrawongAI while developing Prez to be compliant with the OGC API specifications.</p> <p>This test suite is not designed to replace the official test suite and is not able to verify compliance with the standards in any kind of official capacity.</p>"},{"location":"products/tools/prefix-lookup/","title":"Prefix Lookup","text":"<p>Page in development - check back soon</p>"},{"location":"products/tools/prezmanifest/","title":"prezmanifest","text":"<p>A Prez Manifest is an RDF file that describes and links to a set of resources that can be loaded into an RDF database  for Prez to provide access to.</p> <p>To support the use of Prez Manifests, we supply a Python library and command line tool called prezmanifest that  provides a series of functions to work with them. The functions provided are:</p> <ul> <li>documentation</li> <li>validation</li> <li>loading - into aggregated data files or databases</li> <li>labeller</li> </ul> <p>prezmanifest has detailed documentation for installation and use at its repository's home page:</p> <ul> <li>https://github.com/Kurrawong/prezmanifest</li> </ul>"},{"location":"products/tools/prezmanifest/#more-info","title":"More info","text":"<ul> <li>KurrawongAI Service &gt; Tools <ul> <li>for more information on our specialised Knowledge Graph tooling support. </li> </ul> </li> </ul>"},{"location":"products/tools/provworkflow/","title":"ProvWorkflow","text":"<p>ProvWorkflow records the provenance of Python workflows in RDF according to the Prov Workflow Ontology and the Prov Data Model.</p>"},{"location":"products/tools/provworkflow/#installation","title":"Installation","text":"<p>The package is available in PyPi and can be installed with</p> <pre><code>pip install provworkflow\n</code></pre> <p>The source code is available publicly on GitHub at https://github.com/Kurrawong/provworkflow</p>"},{"location":"products/tools/provworkflow/#usage","title":"Usage","text":"<p>ProvWorkflow can be used to record the usage and generation of Entities as part of a workflow process.</p> <p>The following example demonstrates how you might use ProvWorkflow to record the usage of local and remote entities in a script. It also records the generation of some local and remote entities.</p> <p>The workflow is done in two Blocks, each having its own recorded inputs and outputs.</p> <p>Finally the workflow is serialised as RDF in the turtle format and printed to the console.</p> <pre><code>from provworkflow import Workflow, Block, Entity\n\n# set up the Workflow and Block\nw = Workflow(label=\"My Simple Workflow 2\")\nb = Block()\n\n# Block 1\nb.used = [\n    Entity(value=\"local data\"),\n    Entity(uri=\"http://example.com/endpoint\"),\n]\ne_int = Entity(label=\"Internal Entity\")\ne_ext = Entity(label=\"External Entity\", external=True)\nb.generated = [e_int, e_ext]\nw.blocks.append(b)\n\n# Block 2\nb2 = Block()\nb2.used = [Entity(value=\"other local data\"), e_int, e_ext]\nb2.generated.append(\n    Entity(uri=\"http://somewhere-on-s3/d/e/f\", label=\"Final Workflow Output\")\n)\nw.blocks.append(b2)\n\n# print out\nprint(w.prov_to_graph().serialize(format=\"turtle\"))\n</code></pre> <p>Currently provworkflow is only documented in the source code. But a public repository and accompanying tool documentation is on the way.</p> <p>If you would like to see some of our tools in use, we provide an online GUI with some of our most useful tools here.</p> <p>To find out more about other ways KurrawongAI could provide Knowledge Graph tools that solve your data problems, visit the KurrawongAI tools page for more information on our specialised Knowledge Graph Tooling Support. </p>"},{"location":"products/tools/pylode/","title":"pyLODE tool","text":"<p>pyLODE is a Python-based OWL ontology documentation tool based on the Live OWL Documentation Environment tool (LODE) used to generate human-readable HTML documentation for ontologies. </p> <p>To install this yourself, please refer to the RDFLib GitHub repository. If you would like to see some of our supported tools in use, we provide an online GUI with some of our most useful tools here.</p> <p>To find out more about other ways KurrawongAI could provide Knowledge Graph tools that solve your data problems, visit the KurrawongAI tools page for more information on our specialised Knowledge Graph Tooling Support. </p>"},{"location":"products/tools/rdf-converter/","title":"RDF format converter","text":"<p>This conversion tool relies on the Python RDF manipulation library, RDFLib. This allows it to handle more RDF formats than other packages. </p> <p>If you have RDF files that you would like to convert to another RDF format, we provide an online GUI with some of our other useful tools here. </p> <p>To find out more about other ways KurrawongAI could provide Knowledge Graph tools that solve your data problems, visit the KurrawongAI tools page for more information on our specialised Knowledge Graph Tooling Support. </p>"},{"location":"products/tools/rdf-merger/","title":"RDF Merger","text":"<p>Page in development - check back soon</p>"},{"location":"products/tools/shacl-validator/","title":"RDF data SHACL validator","text":"<p>Our RDF SHACL validation tools allows users to validate RDF against either their own specific SHACL validation rules, or select from a pre-loaded set of validators selected from commonly used profiles.</p> <p>If you have RDF that you would like to validate using SHACL inputs, we provide an online GUI with some of our other useful tools here. To find out more about other ways KurrawongAI could provide Knowledge Graph tools that solve your data problems, visit the KurrawongAI tools page for more information on our specialised Knowledge Graph Tooling Support. </p>"},{"location":"products/tools/sparql-parser/","title":"SPARQL parser","text":"<p>This tool utilises Python packages to allow users to input SPARQL queries, validate them, and convert them into other formats. To install this yourself, please refer to the KurrawongAI GitHub repository. </p> <p>If you would like to see some of our supported tools in use, we provide an online GUI with some of our most useful tools here.</p> <p>To find out more about other ways KurrawongAI could provide Knowledge Graph tools that solve your data problems, visit the KurrawongAI tools page for more information on our specialised Knowledge Graph Tooling Support. </p>"},{"location":"products/tools/vocedit/","title":"VocEdit","text":"<p>Page in development - check back soon</p>"},{"location":"products/tools/vocexcel/","title":"VocExcel","text":""},{"location":"products/tools/vocexcel/#python-cli","title":"python #cli","text":"<p>VocExcel is a Python library that converts Excel workbooks into SKOS vocabularies.</p> <p>VocExcel:</p> <ul> <li>uses fixed templates to keep it simple</li> <li>meets particular SKOS profile outcomes (VocPub)</li> <li>is under active development, production use, and is commercially supported</li> </ul> <p>An online version of VocExcel is available at &lt;https://tools.kurrawong.ai/tools/vocexcel&gt;. For other applications, access the GitHub repository here.</p>"},{"location":"products/tools/vocexcel/#creating-vocabularies","title":"Creating vocabularies","text":"<p>The process to create an RDF vocabulary from an Excel template is:</p> <ol> <li>Fill in a copy of an Excel template</li> <li>Process it ** Using one of the options, and export an RDF file ** You can choose to validate the RDF produced while processing</li> </ol>"},{"location":"products/tools/vocexcel/#templates","title":"Templates","text":"<p>The GitHub repository includes a templates/ folder that is to be used to create vocabularies. The templates hopefully contain all the information needed to understand how to fill them in.</p> <p>Use one Excel workbook per vocabulary.</p> <p>Unless you have a good reason to do something different, please use the latest version of the template.</p> <p>Older templates still convert, so if you've used one and like it, keep using it.</p>"},{"location":"products/tools/vocexcel/#examples","title":"Examples","text":"<p>Example filled-in templates versions are given in the <code>tests/</code> folder of the GitHub repository. Just ensure you're looking at examples prefixed with the same template version you are after, e.g. 0.6.0 = 060_simple.xlsx*</p>"},{"location":"products/tools/vocexcel/#processing","title":"Processing","text":"<p>To process an Excel template, you will need to either:</p> <ul> <li>run the VocExcel Python script, or</li> <li>use an Online tool</li> </ul> <p>The Python script can also run as a Python module, i.e. within a larger Python workflow.</p>"},{"location":"products/tools/vocexcel/#installation","title":"Installation","text":"<p>You will need to:</p> <ol> <li>have Python installed on your computer</li> <li>3.6+ required</li> <li>install the required packages in your environment or a virtual environment<ul> <li>you can use the https://python-poetry.org/docs/basic-usage/[Poetry] tool with the pyproject.toml file, or</li> <li>a <code>requirements.txt</code> file is also provided for basic Python PIP package installation</li> </ul> </li> </ol>"},{"location":"products/tools/vocexcel/#running","title":"Running","text":""},{"location":"products/tools/vocexcel/#as-a-command-line-script","title":"As a command line script","text":"<p>The Python script <code>convert.py</code> in the <code>vocexcel/</code> directory can be run on Windows/Unix/Linux/Mac systems like this:</p> <p><code>~$ python convert.py some-excel-file.xlsx</code></p> <p>The command line argument options can be found by typing:</p> <p><code>~$ python convert.py -h</code></p> <p>They are:</p> <pre><code>usage: vocexcel [-h] [-i] [-l] [-v] [-p PROFILE] [-o OUTPUTFILE] [-f {turtle,xml,json-ld}] [-s SHEET] [-t TEMPLATEFILE] [-e ERRORLEVEL] [-m MESSAGELEVEL] [-g LOGFILE] [file_to_convert]\n`positional arguments:\n  file_to_convert       The Excel file to convert to a SKOS vocabulary in RDF or an RDF file to convert to an Excel file (default: None)\n\noptional arguments:\n  -h, --help            show this help message and exit\n  -i, --info            The version and other info of this instance of VocExcel. (default: False)\n  -l, --listprofiles    This flag, if set, must be the only flag supplied. It will cause the program to list all the vocabulary profiles that this converter, indicating both their URI and their short token for use with\n                        the -p (--profile) flag when converting Excel files (default: False)\n  -v, --validate        Validate output file (default: False)\n  -p PROFILE, --profile PROFILE\n                        A profile - a specified information model - for a vocabulary. This tool understands several profiles andyou can choose which one you want to convert the Excel file according to. The list of\n                        profiles - URIs and their corresponding tokens - supported by VocExcel, can be found by running the program with the flag -lp or --listprofiles. (default: vocpub)\n  -o OUTPUTFILE, --outputfile OUTPUTFILE\n                        An optionally-provided output file path. If not provided, output is to standard out. (default: None)\n  -f {turtle,xml,json-ld,graph}, --outputformat {turtle,xml,json-ld,graph}\n                        An optionally-provided output format for RDF outputs. 'graph' returns the in-memory graph object, not serialized RDF. (default: turtle)\n  -s SHEET, --sheet SHEET\n                        The sheet within the target Excel Workbook to process (default: vocabulary)\n  -t TEMPLATEFILE, --templatefile TEMPLATEFILE\n                        An optionally-provided Excel-template file to be used in SKOS-&gt; Excel converion. (default: None)\n  -e ERRORLEVEL, --errorlevel ERRORLEVEL\n                        The minimum severity level which fails validation (default: 1)\n  -m MESSAGELEVEL, --messagelevel MESSAGELEVEL\n                        The minimum severity level printed to console (default: 1)\n  -g LOGFILE, --logfile LOGFILE\n                        The file to write logging output to (default: None)\n</code></pre>"},{"location":"products/tools/vocexcel/#as-a-library","title":"As a library","text":"<p>The convert.py file as a function that you can call to do conversions: <code>excel_to_rdf()</code>, like this:</p> <p><code>from vocexcel import convert</code>from pathlib import Path<code></code>convert.rdf_to_excel(Path(\".\") / \"path\" / \"to\" / \"vocab-file.xlsx\")```</p>"},{"location":"products/tools/vocexcel/#online","title":"Online","text":"<p>https://tools.kurrawong.ai/tools/vocexcel</p>"},{"location":"products/tools/vocexcel/#license","title":"License","text":"<p>This code is licensed using the BSD 3-Clause. See the LICENSE for the deed. Note that Excel is property of Microsoft.</p>"},{"location":"products/tools/vocexcel/#contact","title":"Contact","text":"<p>Commercial support: + info@kurrawong.ai</p> <p>Lead Developer: + Nicholas Car + Data System Architect + https://kurrawong.ai[KurrawongAI] + nick@kurrawong.ai</p>"}]}